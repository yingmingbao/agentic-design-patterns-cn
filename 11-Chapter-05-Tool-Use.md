# Chapter 5: Tool Use (Function Calling) | <mark>ç¬¬äº”ç« ï¼šå·¥å…·ä½¿ç”¨ï¼ˆå‡½æ•°è°ƒç”¨ï¼‰</mark>

## Tool Use Pattern Overview | <mark>å·¥å…·ä½¿ç”¨æ¨¡å¼æ¦‚è¿°</mark>

So far, we've discussed agentic patterns that primarily involve orchestrating interactions between language models and managing the flow of information within the agent's internal workflow (Chaining, Routing, Parallelization, Reflection). However, for agents to be truly useful and interact with the real world or external systems, they need the ability to use Tools.

<mark>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è®¨è®ºçš„æ™ºèƒ½ä½“æ¨¡å¼ä¾§é‡äºåœ¨å¤§è¯­è¨€æ¨¡å‹ä¹‹é—´åè°ƒäº¤äº’å’Œç®¡ç†æ™ºèƒ½ä½“å†…éƒ¨çš„ä¿¡æ¯æµï¼ˆå¦‚æç¤ºé“¾ã€è·¯ç”±ã€å¹¶è¡ŒåŒ–å’Œåæ€æ¨¡å¼ï¼‰ã€‚ä½†å¦‚æœè¦è®©æ™ºèƒ½ä½“çœŸæ­£æœ‰ç”¨ã€èƒ½ä¸ç°å®ä¸–ç•Œæˆ–å¤–éƒ¨ç³»ç»Ÿäº¤äº’ï¼Œå°±å¿…é¡»èµ‹äºˆå®ƒä»¬ä½¿ç”¨å·¥å…·çš„èƒ½åŠ›ã€‚</mark>

The Tool Use pattern, often implemented through a mechanism called Function Calling, enables an agent to interact with external APIs, databases, services, or even execute code. It allows the LLM at the core of the agent to decide when and how to use a specific external function based on the user's request or the current state of the task.

<mark>å·¥å…·ä½¿ç”¨æ¨¡å¼é€šå¸¸é€šè¿‡å‡½æ•°è°ƒç”¨ï¼ˆFunction Callingï¼‰æœºåˆ¶å®ç°ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿä¸å¤–éƒ¨ APIã€æ•°æ®åº“ã€æœåŠ¡äº¤äº’ï¼Œç”šè‡³ç›´æ¥æ‰§è¡Œä»£ç ã€‚å®ƒå…è®¸ä½œä¸ºæ™ºèƒ½ä½“æ ¸å¿ƒçš„å¤§è¯­è¨€æ¨¡å‹æ ¹æ®ç”¨æˆ·è¯·æ±‚æˆ–å½“å‰ä»»åŠ¡çŠ¶æ€ï¼Œæ¥å†³å®šä½•æ—¶ä»¥åŠå¦‚ä½•ä½¿ç”¨ç‰¹å®šçš„å¤–éƒ¨å‡½æ•°ã€‚</mark>

The process typically involves:

<mark>è¿™ä¸ªè¿‡ç¨‹é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š</mark>

1. **Tool Definition:** External functions or capabilities are defined and described to the LLM. This description includes the function's purpose, its name, and the parameters it accepts, along with their types and descriptions.

   <mark><strong>å·¥å…·å®šä¹‰ï¼š</strong>å‘å¤§è¯­è¨€æ¨¡å‹æè¿°å¤–éƒ¨å‡½æ•°æˆ–åŠŸèƒ½ï¼ŒåŒ…æ‹¬å‡½æ•°çš„ç”¨é€”ã€åç§°ï¼Œä»¥åŠæ‰€æ¥å—å‚æ•°çš„ç±»å‹å’Œè¯´æ˜ã€‚</mark>

2. **LLM Decision:** The LLM receives the user's request and the available tool definitions. Based on its understanding of the request and the tools, the LLM decides if calling one or more tools is necessary to fulfill the request.

   <mark><strong>å¤§è¯­è¨€æ¨¡å‹å†³ç­–ï¼š</strong>å¤§è¯­è¨€æ¨¡å‹æ¥æ”¶ç”¨æˆ·çš„è¯·æ±‚å’Œå¯ç”¨çš„å·¥å…·å®šä¹‰ï¼Œå¹¶æ ¹æ®å¯¹ä¸¤è€…çš„ç†è§£åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨ä¸€ä¸ªæˆ–å¤šä¸ªå·¥å…·æ¥å®Œæˆè¯·æ±‚ã€‚</mark>

3. **Function Call Generation:** If the LLM decides to use a tool, it generates a structured output (often a JSON object) that specifies the name of the tool to call and the arguments (parameters) to pass to it, extracted from the user's request.

   <mark><strong>ç”Ÿæˆå‡½æ•°è°ƒç”¨ï¼š</strong>å¦‚æœå¤§è¯­è¨€æ¨¡å‹å†³å®šä½¿ç”¨å·¥å…·ï¼Œå®ƒä¼šç”Ÿæˆç»“æ„åŒ–è¾“å‡ºï¼ˆé€šå¸¸æ˜¯ JSON å¯¹è±¡ï¼‰ï¼ŒæŒ‡æ˜è¦è°ƒç”¨çš„å·¥å…·åç§°ä»¥åŠä»ç”¨æˆ·è¯·æ±‚ä¸­æå–çš„å‚æ•°ã€‚</mark>

4. **Tool Execution:** The agentic framework or orchestration layer intercepts this structured output. It identifies the requested tool and executes the actual external function with the provided arguments.

   <mark><strong>å·¥å…·æ‰§è¡Œï¼š</strong>æ™ºèƒ½ä½“æ¡†æ¶æˆ–ç¼–æ’å±‚æ•è·è¿™ä¸ªç»“æ„åŒ–è¾“å‡ºï¼Œè¯†åˆ«è¦è°ƒç”¨çš„å·¥å…·ï¼Œå¹¶æ ¹æ®ç»™å®šå‚æ•°æ‰§è¡Œç›¸åº”çš„å¤–éƒ¨å‡½æ•°ã€‚</mark>

5. **Observation/Result:** The output or result from the tool execution is returned to the agent.

   <mark><strong>è§‚å¯Ÿ/ç»“æœï¼š</strong>å·¥å…·æ‰§è¡Œçš„è¾“å‡ºæˆ–ç»“æœè¿”å›ç»™æ™ºèƒ½ä½“ã€‚</mark>

6. **LLM Processing (Optional but common):** The LLM receives the tool's output as context and uses it to formulate a final response to the user or decide on the next step in the workflow (which might involve calling another tool, reflecting, or providing a final answer).

   <mark><strong>å¤§è¯­è¨€æ¨¡å‹å¤„ç†ï¼ˆå¯é€‰ï¼Œä½†å¾ˆå¸¸è§ï¼‰ï¼š</strong>å¤§è¯­è¨€æ¨¡å‹æ¥æ”¶å·¥å…·çš„è¾“å‡ºä½œä¸ºä¸Šä¸‹æ–‡ï¼Œå¹¶ç”¨å®ƒæ¥ç”Ÿæˆå¯¹ç”¨æˆ·çš„æœ€ç»ˆå›å¤ï¼Œæˆ–å†³å®šå·¥ä½œæµçš„ä¸‹ä¸€æ­¥ï¼ˆå¯èƒ½æ¶‰åŠè°ƒç”¨å¦ä¸€ä¸ªå·¥å…·ã€è¿›è¡Œåæ€æˆ–æä¾›æœ€ç»ˆç­”æ¡ˆï¼‰ã€‚</mark>

This pattern is fundamental because it breaks the limitations of the LLM's training data and allows it to access up-to-date information, perform calculations it can't do internally, interact with user-specific data, or trigger real-world actions. Function calling is the technical mechanism that bridges the gap between the LLM's reasoning capabilities and the vast array of external functionalities available.

<mark>è¿™ç§æ¨¡å¼å¾ˆå…³é”®ï¼Œå› ä¸ºå®ƒçªç ´äº†å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®çš„å±€é™ï¼Œä½¿å…¶èƒ½å¤Ÿè·å–æœ€æ–°ä¿¡æ¯ã€æ‰§è¡Œå†…éƒ¨æ— æ³•å¤„ç†çš„è®¡ç®—ã€è®¿é—®ç”¨æˆ·ç‰¹å®šçš„æ•°æ®ï¼Œæˆ–è§¦å‘ç°å®ä¸–ç•Œçš„åŠ¨ä½œã€‚å‡½æ•°è°ƒç”¨æ˜¯è¿æ¥å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›ä¸å¤–éƒ¨åŠŸèƒ½çš„æŠ€æœ¯æ¡¥æ¢ã€‚</mark>

While "function calling" aptly describes invoking specific, predefined code functions, it's useful to consider the more expansive concept of "tool calling." This broader term acknowledges that an agent's capabilities can extend far beyond simple function execution. A "tool" can be a traditional function, but it can also be a complex API endpoint, a request to a database, or even an instruction directed at another specialized agent. This perspective allows us to envision more sophisticated systems where, for instance, a primary agent might delegate a complex data analysis task to a dedicated "analyst agent" or query an external knowledge base through its API. Thinking in terms of "tool calling" better captures the full potential of agents to act as orchestrators across a diverse ecosystem of digital resources and other intelligent entities.

<mark>è™½ç„¶ã€Œå‡½æ•°è°ƒç”¨ã€è¿™ä¸ªè¯´æ³•ç¡®å®èƒ½å‡†ç¡®æè¿°è°ƒç”¨é¢„å®šä¹‰ä»£ç å‡½æ•°çš„è¿‡ç¨‹ï¼Œä½†ä»æ›´å¹¿é˜”çš„è§†è§’ç†è§£ã€Œå·¥å…·è°ƒç”¨ã€è¿™ä¸€æ¦‚å¿µæ›´ä¸ºæœ‰ç›Šã€‚é€šè¿‡è¿™ä¸ªæ›´å¹¿ä¹‰çš„æœ¯è¯­ï¼Œæˆ‘ä»¬çœ‹åˆ°æ™ºèƒ½ä½“çš„èƒ½åŠ›å¯ä»¥è¿œè¿œè¶…å‡ºç®€å•çš„å‡½æ•°æ‰§è¡Œã€‚å·¥å…·å¯ä»¥æ˜¯ä¼ ç»Ÿå‡½æ•°ã€å¤æ‚çš„ API æ¥å£ã€æ•°æ®åº“è¯·æ±‚ï¼Œç”šè‡³æ˜¯å‘ç»™å¦ä¸€ä¸ªæ™ºèƒ½ä½“çš„æŒ‡ä»¤ã€‚è¿™ç§è§†è§’è®©æˆ‘ä»¬èƒ½å¤Ÿæ„æƒ³æ›´å¤æ‚çš„ç³»ç»Ÿï¼Œä¾‹å¦‚ï¼Œä¸»æ™ºèƒ½ä½“å¯ä»¥å°†å¤æ‚çš„æ•°æ®åˆ†æä»»åŠ¡å§”æ‰˜ç»™ä¸“é—¨çš„ã€Œåˆ†ææ™ºèƒ½ä½“ã€ï¼Œæˆ–é€šè¿‡ API æŸ¥è¯¢å¤–éƒ¨çŸ¥è¯†åº“ã€‚ã€Œå·¥å…·è°ƒç”¨ã€çš„æ€ç»´æ–¹å¼èƒ½æ›´å¥½åœ°æ•æ‰æ™ºèƒ½ä½“ä½œä¸ºç¼–æ’è€…çš„å…¨éƒ¨æ½œåŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¤šæ ·åŒ–çš„æ•°å­—èµ„æºå’Œå…¶ä»–æ™ºèƒ½ç”Ÿæ€ç³»ç»Ÿä¸­å‘æŒ¥ä½œç”¨ã€‚</mark>

Frameworks like LangChain, LangGraph, and Google Agent Developer Kit (ADK) provide robust support for defining tools and integrating them into agent workflows, often leveraging the native function calling capabilities of modern LLMs like those in the Gemini or OpenAI series. On the "canvas" of these frameworks, you define the tools and then configure agents (typically LLM Agents) to be aware of and capable of using these tools.

<mark>LangChainã€LangGraph å’Œ Google ADK ç­‰æ¡†æ¶å¯ä»¥å¾ˆæ–¹ä¾¿åœ°å®šä¹‰å·¥å…·å¹¶å°†å®ƒä»¬é›†æˆåˆ°æ™ºèƒ½ä½“å·¥ä½œæµä¸­ï¼Œé€šå¸¸ä¼šåˆ©ç”¨ Gemini æˆ– OpenAI ç­‰ç°ä»£å¤§è¯­è¨€æ¨¡å‹çš„åŸç”Ÿå‡½æ•°è°ƒç”¨åŠŸèƒ½ã€‚åœ¨è¿™äº›æ¡†æ¶ä¸­ï¼Œä½ å¯ä»¥å®šä¹‰å·¥å…·ï¼Œå¹¶é€šè¿‡è®¾ç½®è®©æ™ºèƒ½ä½“è¯†åˆ«å’Œä½¿ç”¨è¿™äº›å·¥å…·ã€‚</mark>

Tool Use is a cornerstone pattern for building powerful, interactive, and externally aware agents.

<mark>å·¥å…·ä½¿ç”¨æ˜¯æ„å»ºå¼ºå¤§ã€å¯äº¤äº’ä¸”èƒ½æ„ŸçŸ¥å’Œåˆ©ç”¨å¤–éƒ¨èµ„æºçš„æ™ºèƒ½ä½“çš„å…³é”®æ¨¡å¼ã€‚</mark>

---

## Practical Applications & Use Cases | <mark>å®é™…åº”ç”¨åœºæ™¯</mark>

The Tool Use pattern is applicable in virtually any scenario where an agent needs to go beyond generating text to perform an action or retrieve specific, dynamic information:

<mark>å½“æ™ºèƒ½ä½“éœ€è¦çš„ä¸åªæ˜¯æ–‡æœ¬ç”Ÿæˆï¼Œè€Œæ˜¯æ‰§è¡Œæ“ä½œæˆ–æ£€ç´¢åŠ¨æ€ä¿¡æ¯çš„æ—¶å€™ï¼Œå·¥å…·ä½¿ç”¨æ¨¡å¼å‡ ä¹éƒ½èƒ½æ´¾ä¸Šç”¨åœºã€‚</mark>

**1. Information Retrieval from External Sources:** | <mark><strong>ä»å¤–éƒ¨æ¥æºè·å–ä¿¡æ¯ï¼š</strong></mark>

Accessing real-time data or information that is not present in the LLM's training data.

<mark>è·å–å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®ä¸­æœªåŒ…å«çš„å®æ—¶æ•°æ®æˆ–ä¿¡æ¯ã€‚</mark>

- **Use Case:** A weather agent.
- **Tool:** A weather API that takes a location and returns the current weather conditions.
- **Agent Flow:** User asks, "What's the weather in London?", LLM identifies the need for the weather tool, calls the tool with "London", tool returns data, LLM formats the data into a user-friendly response.

- <mark><strong>ç”¨ä¾‹ï¼š</strong>å¤©æ°”ä¿¡æ¯æ™ºèƒ½ä½“ã€‚</mark>
- <mark><strong>å·¥å…·ï¼š</strong>å¤©æ°”æŸ¥è¯¢æ¥å£ï¼Œå¯è¾“å…¥åœ°ç‚¹å¹¶è¿”å›è¯¥åœ°çš„å®æ—¶å¤©æ°”ã€‚</mark>
- <mark><strong>æ™ºèƒ½ä½“æµç¨‹ï¼š</strong>ç”¨æˆ·æé—®ã€Œä¼¦æ•¦å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿã€ï¼Œå¤§è¯­è¨€æ¨¡å‹è¯†åˆ«å‡ºéœ€è¦ä½¿ç”¨å¤©æ°”å·¥å…·ï¼Œå¹¶ä½¿ç”¨ã€Œä¼¦æ•¦ã€ä½œä¸ºå‚æ•°è°ƒç”¨è¯¥å·¥å…·ï¼Œå·¥å…·è¿”å›æ•°æ®åï¼Œå¤§è¯­è¨€æ¨¡å‹å°†è¿™äº›ä¿¡æ¯æ•´ç†å¹¶ä»¥æ˜“æ‡‚çš„æ–¹å¼è¾“å‡ºç»™ç”¨æˆ·ã€‚</mark>

**2. Interacting with Databases and APIs:** | <mark><strong>ä¸æ•°æ®åº“å’Œæ¥å£äº¤äº’ï¼š</strong></mark>

Performing queries, updates, or other operations on structured data.

<mark>å¯¹ç»“æ„åŒ–æ•°æ®æ‰§è¡ŒæŸ¥è¯¢ã€æ›´æ–°æˆ–å…¶ä»–æ“ä½œã€‚</mark>

- **Use Case:** An e-commerce agent.
- **Tools:** API calls to check product inventory, get order status, or process payments.
- **Agent Flow:** User asks "Is product X in stock?", LLM calls the inventory API, tool returns stock count, LLM tells the user the stock status.

- <mark><strong>ç”¨ä¾‹ï¼š</strong>ç”µå•†å¹³å°æ™ºèƒ½ä½“ã€‚</mark>
- <mark><strong>å·¥å…·ï¼š</strong>é€šè¿‡æ¥å£æ¥æ£€æŸ¥äº§å“åº“å­˜ã€æŸ¥è¯¢è®¢å•çŠ¶æ€æˆ–å¤„ç†æ”¯ä»˜ã€‚</mark>
- <mark><strong>æ™ºèƒ½ä½“æµç¨‹ï¼š</strong>ç”¨æˆ·æé—®ã€Œäº§å“ X æœ‰è´§å—ï¼Ÿã€ï¼Œå¤§è¯­è¨€æ¨¡å‹å…ˆè°ƒç”¨åº“å­˜æ¥å£ï¼Œå·¥å…·è¿”å›åº“å­˜æ•°é‡åï¼Œå¤§è¯­è¨€æ¨¡å‹å‘ç”¨æˆ·åé¦ˆè¯¥äº§å“åº“å­˜æƒ…å†µã€‚</mark>

**3. Performing Calculations and Data Analysis:** | <mark><strong>æ‰§è¡Œè®¡ç®—å’Œæ•°æ®åˆ†æï¼š</strong></mark>

Using external calculators, data analysis libraries, or statistical tools.

<mark>ä½¿ç”¨è®¡ç®—å™¨ã€æ•°æ®åˆ†æåº“æˆ–ç»Ÿè®¡å·¥å…·ã€‚</mark>

- **Use Case:** A financial agent.
- **Tools:** A calculator function, a stock market data API, a spreadsheet tool.
- **Agent Flow:** User asks "What's the current price of AAPL and calculate the potential profit if I bought 100 shares at $150?", LLM calls stock API, gets current price, then calls calculator tool, gets result, formats response.

- <mark><strong>ç”¨ä¾‹ï¼š</strong>é‡‘èé¢†åŸŸæ™ºèƒ½ä½“ã€‚</mark>
- <mark><strong>å·¥å…·ï¼š</strong>è®¡ç®—å™¨å‡½æ•°ã€è‚¡ç¥¨è¡Œæƒ…æ¥å£ã€ç”µå­è¡¨æ ¼å·¥å…·ã€‚</mark>
- <mark><strong>æ™ºèƒ½ä½“æµç¨‹ï¼š</strong>ç”¨æˆ·æé—®ã€Œè‹¹æœå…¬å¸å½“å‰è‚¡ä»·æ˜¯å¤šå°‘ï¼Ÿå¦‚æœæˆ‘ä»¥ 150 ç¾å…ƒä¹°å…¥ 100 è‚¡ï¼Œå¯èƒ½ä¼šèµšå¤šå°‘é’±ï¼Ÿã€ï¼Œå¤§è¯­è¨€æ¨¡å‹ä¼šå…ˆè°ƒç”¨è‚¡ç¥¨è¡Œæƒ…æ¥å£è·å–æœ€æ–°ä»·æ ¼ï¼Œç„¶åè°ƒç”¨è®¡ç®—å™¨å·¥å…·è®¡ç®—æ”¶ç›Šï¼Œæœ€åæŠŠç»“æœæ•´ç†å¹¶è¿”å›ç»™ç”¨æˆ·ã€‚</mark>

**4. Sending Communications:** | <mark><strong>å‘é€æ¶ˆæ¯ï¼š</strong></mark>

Sending emails, messages, or making API calls to external communication services.

<mark>å‘é€ç”µå­é‚®ä»¶ã€æ¶ˆæ¯æˆ–è°ƒç”¨å¤–éƒ¨é€šä¿¡æœåŠ¡çš„æ¥å£ã€‚</mark>

- **Use Case:** A personal assistant agent.
- **Tool:** An email sending API.
- **Agent Flow:** User says, "Send an email to John about the meeting tomorrow.", LLM calls an email tool with the recipient, subject, and body extracted from the request.

- <mark><strong>ç”¨ä¾‹ï¼š</strong>ä¸ªäººåŠ©ç†æ™ºèƒ½ä½“ã€‚</mark>
- <mark><strong>å·¥å…·ï¼š</strong>é‚®ä»¶å‘é€æ¥å£ã€‚</mark>
- <mark><strong>æ™ºèƒ½ä½“æµç¨‹ï¼š</strong>ç”¨æˆ·è¯´ã€Œç»™çº¦ç¿°å‘ä¸€å°å…³äºæ˜å¤©ä¼šè®®çš„é‚®ä»¶ã€ï¼Œå¤§è¯­è¨€æ¨¡å‹ä¼šä»è¯·æ±‚ä¸­æå–æ”¶ä»¶äººã€ä¸»é¢˜å’Œæ­£æ–‡ï¼Œå¹¶è°ƒç”¨é‚®ä»¶æ¥å£å‘é€é‚®ä»¶ã€‚</mark>

**5. Executing Code:** | <mark><strong>æ‰§è¡Œä»£ç ï¼š</strong></mark>

Running code snippets in a safe environment to perform specific tasks.

<mark>åœ¨å—æ§ä¸”å®‰å…¨çš„ç¯å¢ƒä¸­è¿è¡Œä»£ç ç‰‡æ®µä»¥å®Œæˆç‰¹å®šä»»åŠ¡ã€‚</mark>

- **Use Case:** A coding assistant agent.
- **Tool:** A code interpreter.
- **Agent Flow:** User provides a Python snippet and asks, "What does this code do?", LLM uses the interpreter tool to run the code and analyze its output.

- <mark><strong>ç”¨ä¾‹ï¼š</strong>ç¼–ç¨‹åŠ©ç†æ™ºèƒ½ä½“ã€‚</mark>
- <mark><strong>å·¥å…·ï¼š</strong>ä»£ç è§£é‡Šå™¨ã€‚</mark>
- <mark><strong>æ™ºèƒ½ä½“æµç¨‹ï¼š</strong>ç”¨æˆ·æä¾›ä¸€æ®µ Python ä»£ç å¹¶é—®ã€Œè¿™æ®µä»£ç æ˜¯åšä»€ä¹ˆçš„ï¼Ÿã€ï¼Œå¤§è¯­è¨€æ¨¡å‹ä¼šå…ˆä½¿ç”¨ä»£ç è§£é‡Šå™¨è¿è¡Œä»£ç ï¼Œå¹¶æ®æ­¤è¿›è¡Œåˆ†æå’Œè§£é‡Šã€‚</mark>

**6. Controlling Other Systems or Devices:** | <mark><strong>æ§åˆ¶å…¶ä»–ç³»ç»Ÿæˆ–è®¾å¤‡ï¼š</strong></mark>

Interacting with smart home devices, IoT platforms, or other connected systems.

<mark>ä¸æ™ºèƒ½å®¶å±…è®¾å¤‡ã€ç‰©è”ç½‘å¹³å°æˆ–å…¶ä»–è”ç½‘ç³»ç»Ÿäº¤äº’ã€‚</mark>

- **Use Case:** A smart home agent.
- **Tool:** An API to control smart lights.
- **Agent Flow:** User says, "Turn off the living room lights." LLM calls the smart home tool with the command and target device.

- <mark><strong>ç”¨ä¾‹ï¼š</strong>æ™ºèƒ½å®¶å±…æ™ºèƒ½ä½“ã€‚</mark>
- <mark><strong>å·¥å…·ï¼š</strong>æ§åˆ¶æ™ºèƒ½ç¯çš„æ¥å£ã€‚</mark>
- <mark><strong>æ™ºèƒ½ä½“æµç¨‹ï¼š</strong>ç”¨æˆ·è¯´ã€Œå…³æ‰å®¢å…çš„ç¯ã€ï¼Œå¤§è¯­è¨€æ¨¡å‹å°†å¸¦æœ‰å‘½ä»¤å’Œç›®æ ‡è®¾å¤‡ä¿¡æ¯çš„è¯·æ±‚å‘é€ç»™æ™ºèƒ½å®¶å±…å·¥å…·ä»¥æ‰§è¡Œæ“ä½œã€‚</mark>

Tool Use is what transforms a language model from a text generator into an agent capable of sensing, reasoning, and acting in the digital or physical world (see Fig. 1)

<mark>å·¥å…·ä½¿ç”¨æ¨¡å¼å°†è¯­è¨€æ¨¡å‹ä»æ–‡æœ¬ç”Ÿæˆå™¨å˜æˆèƒ½å¤Ÿåœ¨æ•°å­—æˆ–ç°å®ä¸–ç•Œä¸­æ„ŸçŸ¥ã€æ¨ç†å’Œè¡ŒåŠ¨çš„æ™ºèƒ½ä½“ï¼ˆè§å›¾ 1ï¼‰ã€‚</mark>

![Tool Use Examples](/images/chapter05_fig1.jpg)

Fig.1: Some examples of an Agent using Tools

<mark>å›¾ 1ï¼šæ™ºèƒ½ä½“ä½¿ç”¨å·¥å…·çš„ä¸€äº›ç¤ºä¾‹</mark>

---

## Hands-On Code Example (LangChain) | <mark>å®æˆ˜ä»£ç ï¼šä½¿ç”¨ LangChain</mark>

The implementation of tool use within the LangChain framework is a two-stage process. Initially, one or more tools are defined, typically by encapsulating existing Python functions or other runnable components. Subsequently, these tools are bound to a language model, thereby granting the model the capability to generate a structured tool-use request when it determines that an external function call is required to fulfill a user's query.

<mark>åœ¨ LangChain æ¡†æ¶ä¸­ï¼Œä½¿ç”¨å·¥å…·åˆ†ä¸¤ä¸ªæ­¥éª¤ã€‚é¦–å…ˆï¼Œå®šä¹‰ä¸€ä¸ªæˆ–å¤šä¸ªå·¥å…·ï¼Œé€šå¸¸é€šè¿‡å°è£…ç°æœ‰çš„ Python å‡½æ•°æˆ–å…¶ä»–å¯æ‰§è¡Œç»„ä»¶æ¥å®Œæˆã€‚éšåï¼Œå°†è¿™äº›å·¥å…·å’Œå¤§è¯­è¨€æ¨¡å‹ç»‘å®šï¼Œè¿™æ ·å½“å¤§è¯­è¨€æ¨¡å‹åˆ¤æ–­éœ€è¦è°ƒç”¨å¤–éƒ¨å‡½æ•°æ¥å®Œæˆç”¨æˆ·è¯·æ±‚æ—¶ï¼Œå°±èƒ½ç”Ÿæˆç»“æ„åŒ–çš„è°ƒç”¨è¯·æ±‚å¹¶æ‰§è¡Œç›¸åº”æ“ä½œã€‚</mark>

The following implementation will demonstrate this principle by first defining a simple function to simulate an information retrieval tool. Following this, an agent will be constructed and configured to leverage this tool in response to user input. The execution of this example requires the installation of the core LangChain libraries and a model-specific provider package. Furthermore, proper authentication with the selected language model service, typically via an API key configured in the local environment, is a necessary prerequisite.

<mark>ä»¥ä¸‹ä»£ç å°†æ¼”ç¤ºè¿™ä¸€åŸç†ã€‚é¦–å…ˆå®šä¹‰ä¸€ä¸ªç®€å•å‡½æ•°æ¥æ¨¡æ‹Ÿä¿¡æ¯æ£€ç´¢å·¥å…·ï¼Œç„¶åæ„å»ºå¹¶é…ç½®æ™ºèƒ½ä½“ï¼Œä½¿å…¶èƒ½å¤Ÿåˆ©ç”¨è¯¥å·¥å…·å“åº”ç”¨æˆ·è¾“å…¥ã€‚è¿è¡Œæ­¤ç¤ºä¾‹éœ€è¦å…ˆå®‰è£… LangChain çš„æ ¸å¿ƒåº“å’Œç›¸åº”çš„æ¨¡å‹æ¥å…¥åŒ…ï¼Œå¹¶åœ¨æœ¬åœ°ç¯å¢ƒä¸­é…ç½®å¥½ API å¯†é’¥ã€‚</mark>

```python
import os, getpass
import asyncio
import nest_asyncio
from typing import List
from dotenv import load_dotenv
import logging

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool as langchain_tool
from langchain.agents import create_tool_calling_agent, AgentExecutor

# UNCOMMENT
# Prompt the user securely and set API keys as an environment variables
# å®‰å…¨åœ°æç¤ºç”¨æˆ·è®¾ç½® API å¯†é’¥ä½œä¸ºç¯å¢ƒå˜é‡
os.environ["GOOGLE_API_KEY"] = getpass.getpass("Enter your Google API key: ")
os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")

try:
   # A model with function/tool calling capabilities is required.
   # éœ€è¦ä¸€ä¸ªå…·æœ‰å‡½æ•°è°ƒç”¨èƒ½åŠ›çš„æ¨¡å‹ï¼Œè¿™é‡Œä½¿ç”¨ Gemini 2.0 Flashã€‚
   llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
   print(f"âœ… Language model initialized: {llm.model}")
except Exception as e:
   print(f"ğŸ›‘ Error initializing language model: {e}")
   llm = None

# --- Define a Tool ---
# --- å®šä¹‰æ¨¡æ‹Ÿçš„æœç´¢å·¥å…· ---
@langchain_tool
def search_information(query: str) -> str:
   """
   Provides factual information on a given topic. Use this tool to find answers to phrases
   like 'capital of France' or 'weather in London?'.
   # æ¨¡æ‹Ÿæä¾›å…³äºç‰¹å®šæŸ¥è¯¢çš„è¾“å‡ºã€‚ä½¿ç”¨æ­¤å·¥å…·æŸ¥æ‰¾ç±»ä¼¼ã€Œæ³•å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿã€æˆ–ã€Œä¼¦æ•¦çš„å¤©æ°”å¦‚ä½•ï¼Ÿã€è¿™ç±»é—®é¢˜çš„ç­”æ¡ˆã€‚
   """
   print(f"\n--- ğŸ› ï¸ Tool Called: search_information with query: '{query}' ---")
   # Simulate a search tool with a dictionary of predefined results.
   # é€šè¿‡ä¸€ä¸ªå­—å…¸é¢„å®šä¹‰çš„ç»“æœæ¥æ¨¡æ‹Ÿæœç´¢å·¥å…·ã€‚
   simulated_results = {
       "weather in london": "The weather in London is currently cloudy with a temperature of 15Â°C.",
       "capital of france": "The capital of France is Paris.",
       "population of earth": "The estimated population of Earth is around 8 billion people.",
       "tallest mountain": "Mount Everest is the tallest mountain above sea level.",
       "default": f"Simulated search result for '{query}': No specific information found, but the topic seems interesting."
   }
   result = simulated_results.get(query.lower(), simulated_results["default"])
   print(f"--- TOOL RESULT: {result} ---")
   return result

tools = [search_information]

# --- Create a Tool-Calling Agent ---
# --- åˆ›å»ºä¸€ä¸ªä½¿ç”¨å·¥å…·çš„æ™ºèƒ½ä½“ ---
if llm:
   # This prompt template requires an `agent_scratchpad` placeholder for the agent's internal steps.
   # è¿™ä¸ªæç¤ºæ¨¡æ¿éœ€è¦ä¸€ä¸ª `agent_scratchpad` å ä½ç¬¦ï¼Œç”¨äºè®°å½•æ™ºèƒ½ä½“çš„å†…éƒ¨æ­¥éª¤ã€‚
   agent_prompt = ChatPromptTemplate.from_messages([
       ("system", "You are a helpful assistant."),
       ("human", "{input}"),
       ("placeholder", "{agent_scratchpad}"),
   ])

   # Create the agent, binding the LLM, tools, and prompt together.
   # ä½¿ç”¨å®šä¹‰å¥½çš„å¤§è¯­è¨€æ¨¡å‹ã€å·¥å…·å’Œæç¤ºè¯æ¨¡æ¿æ„å»ºæ™ºèƒ½ä½“ã€‚
   agent = create_tool_calling_agent(llm, tools, agent_prompt)

   # AgentExecutor is the runtime that invokes the agent and executes the chosen tools.
   # The 'tools' argument is not needed here as they are already bound to the agent.
   # AgentExecutor è´Ÿè´£è°ƒç”¨æ™ºèƒ½ä½“å¹¶è¿è¡Œå…¶é€‰æ‹©å·¥å…·çš„è¿è¡Œæ—¶ç»„ä»¶ã€‚
   # è¿™é‡Œçš„ 'tools' å‚æ•°å¯ä»¥ä¸éœ€è¦äº†ï¼Œå› ä¸ºå®ƒä»¬å·²ç»ç»‘å®šåˆ°æ™ºèƒ½ä½“ä¸Šäº†ã€‚
   agent_executor = AgentExecutor(agent=agent, verbose=True, tools=tools)

async def run_agent_with_tool(query: str):
   """
   Invokes the agent executor with a query and prints the final response.
   æ‰§è¡Œæ™ºèƒ½ä½“å¹¶æ‰“å°æœ€ç»ˆè¾“å‡ºä¿¡æ¯ã€‚
   """
   print(f"\n--- ğŸƒ Running Agent with Query: '{query}' ---")
   try:
       response = await agent_executor.ainvoke({"input": query})
       print("\n--- âœ… Final Agent Response ---")
       print(response["output"])
   except Exception as e:
       print(f"\nğŸ›‘ An error occurred during agent execution: {e}")

async def main():
   """
   Runs all agent queries concurrently.
   å¹¶å‘è¿è¡Œæ‰€æœ‰æ™ºèƒ½ä½“æŸ¥è¯¢ä»»åŠ¡ã€‚
   """
   tasks = [
       run_agent_with_tool("What is the capital of France?"),
       run_agent_with_tool("What's the weather like in London?"),
       run_agent_with_tool("Tell me something about dogs.") # Should trigger the default tool response
   ]
   await asyncio.gather(*tasks)

nest_asyncio.apply()
asyncio.run(main())
```

è¯‘è€…æ³¨ï¼š[Colab ä»£ç ](https://colab.research.google.com/drive/1PNsMB2kcCP-iPgpYamG11bGkBiP3QViz#scrollTo=FW3Eh5_OjUea) å·²ç»´æŠ¤åœ¨[æ­¤å¤„](/codes/Chapter-05-Tool-Use-LangChain-Example.py)ï¼Œå¹¶æ·»åŠ äº†è¾“å‡ºç¤ºä¾‹ã€‚

The code sets up a tool-calling agent using the LangChain library and the Google Gemini model. It defines a <code>search_information</code> tool that simulates providing factual answers to specific queries. The tool has predefined responses for "weather in london," "capital of france," and "population of earth," and a default response for other queries. A <code>ChatGoogleGenerativeAI</code> model is initialized, ensuring it has tool-calling capabilities. A <code>ChatPromptTemplate</code> is created to guide the agent's interaction. The <code>create_tool_calling_agent</code> function is used to combine the language model, tools, and prompt into an agent. An <code>AgentExecutor</code> is then set up to manage the agent's execution and tool invocation. The <code>run_agent_with_tool</code> asynchronous function is defined to invoke the agent with a given query and print the result. The <code>main</code> asynchronous function prepares multiple queries to be run concurrently. These queries are designed to test both the specific and default responses of the <code>search_information</code> tool. Finally, the <code>asyncio.run(main())</code> call executes all the agent tasks. The code includes checks for successful LLM initialization before proceeding with agent setup and execution.

<mark>ä»¥ä¸Šä»£ç ä½¿ç”¨äº† LangChain åº“å’Œ Google Gemini æ¨¡å‹æ„å»ºäº†ä¸€ä¸ªä½¿ç”¨å·¥å…·çš„æ™ºèƒ½ä½“ã€‚</mark>

<mark>é¦–å…ˆå®šä¹‰äº† <code>search_information</code> å·¥å…·ï¼Œç”¨äºæ¨¡æ‹Ÿæ£€ç´¢ç‰¹å®šé—®é¢˜çš„äº‹å®ç­”æ¡ˆï¼Œæ¯”å¦‚ã€Œä¼¦æ•¦å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿã€ã€ã€Œæ³•å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿã€å’Œã€Œåœ°çƒçš„äººå£æ˜¯å¤šå°‘ï¼Ÿã€ï¼Œå¦‚æœæ˜¯å…¶ä»–é—®é¢˜å°±è¿”å›ä¸€ä¸ªå…œåº•å›å¤ã€‚</mark>

<mark>æ¥ç€åˆå§‹åŒ–äº†ä¸€ä¸ªå…·å¤‡å·¥å…·è°ƒç”¨èƒ½åŠ›çš„ <code>ChatGoogleGenerativeAI</code> æ¨¡å‹ï¼Œå¹¶åˆ›å»ºäº†ç”¨äºå¼•å¯¼å¯¹è¯çš„ <code>ChatPromptTemplate</code>ã€‚é€šè¿‡ <code>create_tool_calling_agent</code> å°†ä¸Šè¿°å®šä¹‰çš„æ¨¡å‹ã€å·¥å…·å’Œæç¤ºç»„åˆæˆæ™ºèƒ½ä½“ï¼Œå¹¶ç”¨ <code>AgentExecutor</code> è´Ÿè´£å…·ä½“çš„æ‰§è¡Œä¸å·¥å…·è°ƒç”¨ä»»åŠ¡ã€‚</mark>

<mark>ä»£ç ä¸­è¿˜ç”¨å¼‚æ­¥å‡½æ•° <code>run_agent_with_tool</code>ï¼Œç”¨äºç”¨æŒ‡å®šè¾“å…¥è°ƒç”¨æ™ºèƒ½ä½“ï¼Œå¹¶æ‰“å°æœ€ç»ˆè¾“å‡ºç»“æœã€‚ä¸»å¼‚æ­¥å‡½æ•° <code>main</code> åˆ™å‡†å¤‡äº†å¤šæ¡æŸ¥è¯¢ï¼Œä»¥æµ‹è¯•å·¥å…· <code>search_information</code> çš„è¾“å‡ºæƒ…å†µï¼ŒåŒ…æ‹¬é¢„å®šä¹‰çš„æŸ¥è¯¢å’Œå…œåº•å›å¤ã€‚</mark>

<mark>æ‰§è¡Œå‰ä»£ç ä¼šæ£€æŸ¥æ¨¡å‹æ˜¯å¦æˆåŠŸåˆå§‹åŒ–ï¼Œæœ€åé€šè¿‡ <code>asyncio.run(main())</code> å¯åŠ¨æ‰€æœ‰ä»»åŠ¡ã€‚</mark>

---

## Hands-On Code Example (CrewAI) | <mark>å®æˆ˜ä»£ç ï¼šCrewAI</mark>

This code provides a practical example of how to implement function calling (Tools) within the CrewAI framework. It sets up a simple scenario where an agent is equipped with a tool to look up information. The example specifically demonstrates fetching a simulated stock price using this agent and tool.

<mark>ä»¥ä¸‹ä»£ç å±•ç¤ºäº†ä½¿ç”¨ CrewAI æ¡†æ¶å®ç°å‡½æ•°è°ƒç”¨çš„å®é™…ç¤ºä¾‹ã€‚åœºæ™¯å¾ˆç®€å•ï¼šä¸ºæ™ºèƒ½ä½“é…å¤‡ç”¨äºæŸ¥æ‰¾ä¿¡æ¯çš„å·¥å…·ï¼Œå¹¶é€šè¿‡è¯¥æ™ºèƒ½ä½“å’Œå·¥å…·æ¥è·å–æ¨¡æ‹Ÿçš„è‚¡ç¥¨ä»·æ ¼ã€‚</mark>

```python
# pip install crewai langchain-openai

import os
from crewai import Agent, Task, Crew
from crewai.tools import tool
import logging

# --- Best Practice: Configure Logging ---
# A basic logging setup helps in debugging and tracking the crew's execution.
# --- æœ€ä½³å®è·µï¼šé…ç½®æ—¥å¿— ---
# è‰¯å¥½çš„æ—¥å¿—è®¾ç½®æœ‰åŠ©äºè°ƒè¯•å’Œè¿½è¸ª crewAI çš„æ‰§è¡Œè¿‡ç¨‹ã€‚
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Set up your API Key ---
# For production, it's recommended to use a more secure method for key management
# like environment variables loaded at runtime or a secret manager.
# --- è®¾ç½®ä½ çš„ API å¯†é’¥ ---
# åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ¨èä½¿ç”¨æ›´å®‰å…¨çš„å¯†é’¥ç®¡ç†æ–¹æ³•ï¼Œ
# ä¾‹å¦‚åœ¨è¿è¡Œæ—¶åŠ è½½ç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨å¯†é’¥ç®¡ç†å™¨ã€‚
#
# Set the environment variable for your chosen LLM provider (e.g., OPENAI_API_KEY)
# æ ¹æ®ä½ é€‰æ‹©çš„æ¨¡å‹æä¾›å•†è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚ OPENAI_API_KEYï¼‰
# os.environ["OPENAI_API_KEY"] = "YOUR_API_KEY"
# os.environ["OPENAI_MODEL_NAME"] = "gpt-4o"

# --- 1. Refactored Tool: Returns Clean Data ---
# The tool now returns raw data (a float) or raises a standard Python error.
# This makes it more reusable and forces the agent to handle outcomes properly.
# --- 1. é‡æ„åçš„å·¥å…· ---
# è¯¥å·¥å…·ç°åœ¨è¿”å›æ¨¡æ‹Ÿçš„è‚¡ä»·ï¼ˆä¸€ä¸ªæµ®ç‚¹æ•°ï¼‰æˆ–æŠ›å‡ºæ ‡å‡†çš„ Python é”™è¯¯ã€‚
# è¿™æ ·å¯ä»¥æé«˜å¯é‡ç”¨æ€§ï¼Œå¹¶ç¡®ä¿æ™ºèƒ½ä½“åœ¨å¤„ç†ç»“æœæ—¶é‡‡å–é€‚å½“çš„å¤„ç†æªæ–½ã€‚
@tool("Stock Price Lookup Tool")
def get_stock_price(ticker: str) -> float:
    """
    Fetches the latest simulated stock price for a given stock ticker symbol.
    Returns the price as a float. Raises a ValueError if the ticker is not found.
    è·å–æŒ‡å®šè‚¡ç¥¨ä»£ç çš„æœ€æ–°æ¨¡æ‹Ÿè‚¡ä»·ä¿¡æ¯ã€‚
    è¿”å›è¯¥è‚¡ç¥¨çš„ä»·æ ¼ï¼ˆæµ®ç‚¹æ•°ï¼‰ã€‚å¦‚æœæ‰¾ä¸åˆ°è¯¥ä»£ç ï¼Œä¼šæŠ›å‡º ValueError å¼‚å¸¸ã€‚
    """
    logging.info(f"Tool Call: get_stock_price for ticker '{ticker}'")
    simulated_prices = {
        "AAPL": 178.15,
        "GOOGL": 1750.30,
        "MSFT": 425.50,
    }
    price = simulated_prices.get(ticker.upper())

    if price is not None:
        return price
    else:
        # Raising a specific error is better than returning a string.
        # The agent is equipped to handle exceptions and can decide on the next action.
        # ä¸å…¶è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä¸å¦‚æŠ›å‡ºä¸€ä¸ªæ˜ç¡®çš„é”™è¯¯ï¼Œè¿™æ ·æ›´æ¸…æ™°ä¹Ÿä¾¿äºå¤„ç†ã€‚
        # è¯¥æ™ºèƒ½ä½“å…·å¤‡å¼‚å¸¸å¤„ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨å‘ç”Ÿé—®é¢˜æ—¶åˆ¤æ–­å¹¶é€‰æ‹©åˆé€‚çš„åç»­åŠ¨ä½œã€‚
        raise ValueError(f"Simulated price for ticker '{ticker.upper()}' not found.")


# --- 2. Define the Agent ---
# The agent definition remains the same, but it will now leverage the improved tool.
# --- 2. å®šä¹‰æ™ºèƒ½ä½“ ---
# æ™ºèƒ½ä½“çš„å®šä¹‰ä»ç„¶æ²¿ç”¨åŸæœ‰å†…å®¹ï¼Œä¸è¿‡ç°åœ¨ä¼šä½¿ç”¨å¢å¼ºåçš„å·¥å…·ã€‚
financial_analyst_agent = Agent(
  role='Senior Financial Analyst',
  goal='Analyze stock data using provided tools and report key prices.',
  backstory="You are an experienced financial analyst adept at using data sources to find stock information. You provide clear, direct answers.",
  verbose=True,
  tools=[get_stock_price],
  # Allowing delegation can be useful, but is not necessary for this simple task.
  # å…è®¸å§”æ‰˜åœ¨æŸäº›æƒ…å†µä¸‹å¾ˆæœ‰ç”¨ï¼Œä½†å¯¹äºè¿™ä¸ªç®€å•çš„ä»»åŠ¡å¹¶éå¿…éœ€ã€‚
  allow_delegation=False,
)

# --- 3. Refined Task: Clearer Instructions and Error Handling ---
# The task description is more specific and guides the agent on how to react
# to both successful data retrieval and potential errors.
# --- 3. ä¼˜åŒ–åçš„ä»»åŠ¡ï¼šæä¾›æ›´æ¸…æ™°çš„æŒ‡å¼•ä¸æ›´å®Œå–„çš„é”™è¯¯å¤„ç† ---
# ä»»åŠ¡æè¿°æ›´åŠ è¯¦å°½ï¼Œèƒ½å¤ŸæŒ‡å¯¼æ™ºèƒ½ä½“åœ¨æŸ¥è¯¢æˆåŠŸå’ŒæŠ›å‡ºé”™è¯¯æ—¶éƒ½é‡‡å–æ­£ç¡®çš„å¤„ç†ã€‚
analyze_aapl_task = Task(
  description=(
      "What is the current simulated stock price for Apple (ticker: AAPL)? "
      "Use the 'Stock Price Lookup Tool' to find it. "
      "If the ticker is not found, you must report that you were unable to retrieve the price."
  ),
  expected_output=(
      "A single, clear sentence stating the simulated stock price for AAPL. "
      "For example: 'The simulated stock price for AAPL is $178.15.' "
      "If the price cannot be found, state that clearly."
  ),
  agent=financial_analyst_agent,
)

# --- 4. Formulate the Crew ---
# The crew orchestrates how the agent and task work together.
# --- 4. æ„å»º Crew å®ä¾‹ ---
# ç”±è¯¥å®ä¾‹æ¥è´Ÿè´£åè°ƒæ™ºèƒ½ä½“å’Œä»»åŠ¡ã€‚
financial_crew = Crew(
  agents=[financial_analyst_agent],
  tasks=[analyze_aapl_task],
  verbose=True # Set to False for less detailed logs in production
)

# --- 5. Run the Crew within a Main Execution Block ---
# Using a __name__ == "__main__": block is a standard Python best practice.
# --- 5. åœ¨ä¸»ç¨‹åºä¸­è¿è¡Œ ---
# ä½¿ç”¨ __name__ == "__main__": ä»£ç å—æ˜¯ Python çš„æœ€ä½³å®è·µã€‚
def main():
    """Main function to run the crew."""
    # Check for API key before starting to avoid runtime errors.
    # åœ¨å¯åŠ¨ Crew ä¹‹å‰ï¼Œæ£€æŸ¥ OPENAI_API_KEY ç¯å¢ƒå˜é‡æ˜¯å¦å·²è®¾ç½®ã€‚
    if not os.environ.get("OPENAI_API_KEY"):
        print("ERROR: The OPENAI_API_KEY environment variable is not set.")
        print("Please set it before running the script.")
        return

    print("\n## Starting the Financial Crew...")
    print("---------------------------------")

    # The kickoff method starts the execution.
    # ä½¿ç”¨ kickoff æ–¹æ³•å¯åŠ¨æ‰§è¡Œã€‚
    result = financial_crew.kickoff()

    print("\n---------------------------------")
    print("## Crew execution finished.")
    print("\nFinal Result:\n", result)

if __name__ == "__main__":
    main()
```

è¯‘è€…æ³¨ï¼š[Colab ä»£ç ](https://colab.research.google.com/drive/1TBcatcgnntrm31kfIzENsSMNYwMNLUOh) å·²ç»´æŠ¤åœ¨[æ­¤å¤„](/codes/Chapter-05-Tool-Use-CrewAI-Example.py)ï¼Œå¹¶æ·»åŠ äº†è¾“å‡ºç¤ºä¾‹ã€‚

This code demonstrates a simple application using the Crew.ai library to simulate a financial analysis task. It defines a custom tool, <code>get_stock_price</code>, that simulates looking up stock prices for predefined tickers. The tool is designed to return a floating-point number for valid tickers or raise a <code>ValueError</code> for invalid ones. A Crew.ai Agent named <code>financial_analyst_agent</code> is created with the role of a Senior Financial Analyst. This agent is given the <code>get_stock_price</code> tool to interact with. A Task is defined, <code>analyze_aapl_task</code>, specifically instructing the agent to find the simulated stock price for AAPL using the tool. The task description includes clear instructions on how to handle both success and failure cases when using the tool. A Crew is assembled, comprising the <code>financial_analyst_agent</code> and the <code>analyze_aapl_task</code>. The <code>verbose</code> setting is enabled for both the agent and the crew to provide detailed logging during execution. The main part of the script runs the crew's task using the <code>kickoff()</code> method within a standard <code>if __name__ == "__main__":</code> block. Before starting the crew, it checks if the <code>OPENAI_API_KEY</code> environment variable is set, which is required for the agent to function. The result of the crew's execution, which is the output of the task, is then printed to the console. The code also includes basic logging configuration for better tracking of the crew's actions and tool calls. It uses environment variables for API key management, though it notes that more secure methods are recommended for production environments. In short, the core logic showcases how to define tools, agents, and tasks to create a collaborative workflow in Crew.ai.

<mark>ä»¥ä¸Šä»£ç æ¼”ç¤ºäº†ä¸€ä¸ªä½¿ç”¨ Crew.ai åº“æ¥æ¨¡æ‹Ÿé‡‘èåˆ†æä»»åŠ¡çš„ç®€å•åº”ç”¨ã€‚</mark>

<mark>é¦–å…ˆå®šä¹‰äº†å·¥å…· <code>get_stock_price</code>ï¼Œç”¨äºæ¨¡æ‹ŸæŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨ä»£ç çš„ä»·æ ¼ï¼Œå½“è‚¡ç¥¨ä»£ç æ˜¯é¢„å®šä¹‰çš„æœ‰æ•ˆä»£ç æ—¶è¿”å›æ¨¡æ‹Ÿçš„ä»·æ ¼ï¼Œå¦‚æœæ˜¯å…¶ä»–ä»£ç åˆ™æŠ›å‡º <code>ValueError</code> å¼‚å¸¸ã€‚</mark>

<mark>æ¥ç€åˆ›å»ºä¸€ä¸ªåä¸º <code>financial_analyst_agent</code> çš„ Crew.ai æ™ºèƒ½ä½“ï¼Œå…¶è¢«èµ‹äºˆçš„è§’è‰²æ˜¯é«˜çº§é‡‘èåˆ†æå¸ˆï¼Œå…è®¸ä½¿ç”¨ <code>get_stock_price</code> å·¥å…·è¿›è¡Œäº¤äº’ã€‚</mark>

<mark>éšåå®šä¹‰äº† <code>analyze_aapl_task</code> ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡è¦æ±‚æ™ºèƒ½ä½“ä½¿ç”¨å·¥å…·æŸ¥æ‰¾è‹¹æœï¼ˆè‚¡ç¥¨ä»£ç ä¸º AAPLï¼‰çš„è‚¡ä»·ï¼Œå¹¶è¯¦ç»†æè¿°äº†å¦‚ä½•å¤„ç†æˆåŠŸå’Œå¤±è´¥çš„æƒ…å½¢ã€‚</mark>

<mark>ç„¶ååŸºäºä¸Šè¿°çš„ <code>financial_analyst_agent</code> æ™ºèƒ½ä½“å’Œ <code>analyze_aapl_task</code> ä»»åŠ¡æ„å»ºäº† <code>Crew</code> å®ä¾‹ï¼Œå¹¶è®¾ç½® <code>verbose</code> ä¸º true ä»¥ä¾¿åœ¨æ‰§è¡ŒæœŸé—´è¾“å‡ºè¯¦ç»†æ—¥å¿—ã€‚</mark>

<mark>è„šæœ¬çš„ä¸»ä½“éƒ¨åˆ†åœ¨æ ‡å‡†çš„ <code>if __name__ == "__main__":</code> å—å†…ï¼Œä½¿ç”¨ <code>kickoff()</code> æ–¹æ³•è¿è¡Œ Crew å®ä¾‹çš„ä»»åŠ¡ã€‚åœ¨å¯åŠ¨ Crew ä¹‹å‰ï¼Œæ£€æŸ¥ <code>OPENAI_API_KEY</code> ç¯å¢ƒå˜é‡æ˜¯å¦å·²è®¾ç½®ï¼Œè¿™æ˜¯æ™ºèƒ½ä½“è¿è¡Œæ‰€å¿…éœ€çš„ã€‚</mark>

<mark>Crew æ‰§è¡Œçš„ç»“æœæœ€ç»ˆè¢«æ‰“å°åˆ°æ§åˆ¶å°ã€‚ä»£ç ä¸­è¿˜åŒ…æ‹¬äº†æ—¥å¿—é…ç½®ï¼Œä»¥ä¾¿èƒ½æ›´å¥½åœ°è¿½è¸ª Crew çš„è¡Œä¸ºå’Œå·¥å…·è°ƒç”¨ã€‚å®ƒä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç† API å¯†é’¥ï¼Œä½†åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ¨èä½¿ç”¨æ›´å®‰å…¨çš„æ–¹æ³•ã€‚</mark>

<mark>ç®€è€Œè¨€ä¹‹ï¼Œè¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨ Crew.ai ä¸­å®šä¹‰å·¥å…·ã€æ™ºèƒ½ä½“å’Œä»»åŠ¡ï¼Œä»¥åˆ›å»ºåä½œå¼çš„å·¥ä½œæµã€‚</mark>

---

## Hands-on code (Google ADK) | <mark>å®æˆ˜ä»£ç ï¼šä½¿ç”¨ Google ADK</mark>

The Google Agent Developer Kit (ADK) includes a library of natively integrated tools that can be directly incorporated into an agent's capabilities.

<mark>Google å¼€å‘è€…å¥—ä»¶ï¼ˆADKï¼‰å†…ç½®äº†ä¸°å¯Œçš„å·¥å…·ï¼Œè¿™äº›å·¥å…·å¯ä»¥ç›´æ¥æ•´åˆåˆ°æ™ºèƒ½ä½“ä¸­ï¼Œæ–¹ä¾¿æ‰©å±•å…¶åŠŸèƒ½ã€‚</mark>

**Google search:** A primary example of such a component is the Google Search tool. This tool serves as a direct interface to the Google Search engine, equipping the agent with the functionality to perform web searches and retrieve external information.

<mark><strong>Google æœç´¢ï¼š</strong>Google æœç´¢å·¥å…·å°±æ˜¯å…¸å‹çš„ä¾‹å­ï¼Œå®ƒæä¾› Google æœç´¢çš„æ¥å£ï¼Œå¯ä»¥ä¸ºæ™ºèƒ½ä½“æä¾›ç½‘ç»œæœç´¢å’Œå¤–éƒ¨ä¿¡æ¯æ£€ç´¢çš„åŠŸèƒ½ã€‚</mark>

```python
from google.adk.agents import Agent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.adk.tools import google_search
from google.genai import types
import nest_asyncio
import asyncio

# Define variables required for Session setup and Agent execution
# å®šä¹‰ä¼šè¯å’Œæ™ºèƒ½ä½“æ‰§è¡Œæ‰€éœ€çš„å˜é‡
APP_NAME="Google Search_agent"
USER_ID="user1234"
SESSION_ID="1234"

# Define Agent with access to search tool
# å®šä¹‰ä¸€ä¸ªå¯ä»¥ä½¿ç”¨æœç´¢åŠŸèƒ½çš„æ™ºèƒ½ä½“
root_agent = Agent(
   name="basic_search_agent",
   model="gemini-2.0-flash-exp",
   description="Agent to answer questions using Google Search.",
   instruction="I can answer your questions by searching the internet. Just ask me anything!",
   tools=[google_search] # Google Search is a pre-built tool to perform Google searches. Google Search æ˜¯ä¸€ä¸ªå†…ç½®çš„å·¥å…·ï¼Œç”¨æ¥æ‰§è¡Œ Google æœç´¢ã€‚
)

# Agent Interaction
# æ™ºèƒ½ä½“è°ƒç”¨å‡½æ•°
async def call_agent(query):
   """
   Helper function to call the agent with a query.
   è¾…åŠ©å‡½æ•°ï¼Œä¼ å…¥æŸ¥è¯¢å‚æ•°è°ƒç”¨æ™ºèƒ½ä½“ã€‚
   """

   # Session and Runner
   # ä¼šè¯å’Œæ‰§è¡Œå™¨
   session_service = InMemorySessionService()
   session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)
   runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)

   content = types.Content(role='user', parts=[types.Part(text=query)])
   events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)


   for event in events:
       if event.is_final_response():
           final_response = event.content.parts[0].text
           print("Agent Response: ", final_response)

nest_asyncio.apply()
asyncio.run(call_agent("what's the latest ai news?"))
```

è¯‘è€…æ³¨ï¼š[Colab ä»£ç ](https://colab.research.google.com/drive/1qFpzmHYomA4vbtuuV1DJrW_cpAZAbY_m) å·²ç»´æŠ¤åœ¨[æ­¤å¤„](/codes/Chapter-05-Tool-Use-ADK-Example-Google-Search.py)ï¼Œå¹¶æ·»åŠ äº†è¾“å‡ºç¤ºä¾‹ã€‚

This code demonstrates how to create and use a basic agent powered by the Google ADK for Python. The agent is designed to answer questions by utilizing Google Search as a tool. First, necessary libraries from IPython, google.adk, and google.genai are imported. Constants for the application name, user ID, and session ID are defined. An Agent instance named "basic_search_agent" is created with a description and instructions indicating its purpose. It's configured to use the Google Search tool, which is a pre-built tool provided by the ADK. An <code>InMemorySessionService</code> (see Chapter 8) is initialized to manage sessions for the agent. A new session is created for the specified application, user, and session IDs. A <code>Runner</code> is instantiated, linking the created agent with the session service. This runner is responsible for executing the agent's interactions within a session. A helper function <code>call_agent</code> is defined to simplify the process of sending a query to the agent and processing the response. Inside <code>call_agent</code>, the user's query is formatted as a <code>types.Content</code> object with the role 'user'. The <code>runner.run</code> method is called with the user ID, session ID, and the new message content. The <code>runner.run</code> method returns a list of events representing the agent's actions and responses. The code iterates through these events to find the final response. If an event is identified as the final response, the text content of that response is extracted. The extracted agent response is then printed to the console. Finally, the <code>call_agent</code> function is called with the query "what's the latest ai news?" to demonstrate the agent in action.

<mark>ä»¥ä¸Šä»£ç æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Python ç‰ˆæœ¬çš„ Google ADK åˆ›å»ºä¸€ä¸ªç®€å•çš„æ™ºèƒ½ä½“ï¼Œè¯¥æ™ºèƒ½ä½“å¯ä»¥é€šè¿‡å†…ç½®çš„ Google æœç´¢å·¥å…·æ¥å›ç­”é—®é¢˜ã€‚</mark>

<mark>é¦–å…ˆä» <code>IPython</code>ã€<code>google.adk</code> å’Œ <code>google.genai</code> å¯¼å…¥å¿…è¦çš„åº“ï¼Œå¹¶å®šä¹‰åº”ç”¨åç§°ã€ç”¨æˆ· ID å’Œä¼šè¯ ID ç­‰å¸¸é‡ã€‚</mark>

<mark>æ¥ç€åˆ›å»ºä¸€ä¸ªåä¸º<code>basic_search_agent</code> çš„æ™ºèƒ½ä½“å®ä¾‹ï¼Œè¯¦ç»†æè¿°æ™ºèƒ½ä½“çš„åŠŸèƒ½å’ŒæŒ‡ä»¤ï¼ŒåŒæ—¶å£°æ˜ä½¿ç”¨ ADK å†…é¢„ç½®çš„ Google æœç´¢å·¥å…·ã€‚</mark>

<mark>ç„¶ååœ¨æ™ºèƒ½ä½“è¾…åŠ©å‡½æ•°å†…ï¼Œå…ˆåˆå§‹åŒ–ä¸€ä¸ª <code>InMemorySessionService</code>ï¼ˆè¯¦è§ç¬¬å…«ç« ï¼‰æ¥ç®¡ç†æ™ºèƒ½ä½“çš„ä¼šè¯ï¼Œå¹¶ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„åº”ç”¨ã€ç”¨æˆ·å’Œä¼šè¯ ID ç­‰å¸¸é‡åˆ›å»ºæ–°ä¼šè¯ã€‚æ¥ç€åˆ›å»º <code>Runner</code> å®ä¾‹ï¼Œå°†åˆ›å»ºçš„æ™ºèƒ½ä½“ä¸ä¸Šè¿°ä¼šè¯æœåŠ¡è¿æ¥èµ·æ¥ï¼Œè´Ÿè´£åœ¨ä¼šè¯ä¸­æ‰§è¡Œæ™ºèƒ½ä½“çš„äº¤äº’ã€‚è¿™ä¸ªè¾…åŠ©å‡½æ•° <code>call_agent</code> å°è£…äº†å‘æ™ºèƒ½ä½“å‘é€æŸ¥è¯¢å’Œå¤„ç†å“åº”çš„è¿‡ç¨‹ï¼Œç”¨æˆ·çš„æŸ¥è¯¢è¢«å°è£…æˆè§’è‰²ä¸ºã€Œuserã€çš„ <code>types.Content</code> å¯¹è±¡ï¼Œè¯¥å¯¹è±¡å’Œç”¨æˆ· IDã€ä¼šè¯ ID ä¸€èµ·ä¼ ç»™ <code>runner.run</code> æ–¹æ³•å¯åŠ¨æ‰§è¡Œã€‚è¯¥æ–¹æ³•éšåè¿”å›äº‹ä»¶åˆ—è¡¨ï¼Œä»£è¡¨æ™ºèƒ½ä½“çš„è¡Œä¸ºå’Œå“åº”ã€‚ä»£ç éå†è¿™äº›äº‹ä»¶ä»¥æ‰¾åˆ°æœ€ç»ˆå“åº”ï¼Œå¦‚æœæŸä¸ªäº‹ä»¶è¢«è¯†åˆ«ä¸ºæœ€ç»ˆå“åº”ï¼Œåˆ™æå–å…¶æ–‡æœ¬å†…å®¹å¹¶è¾“å‡ºåˆ°æ§åˆ¶å°ã€‚</mark>

<mark>æœ€åä»£ç ä¼ å…¥é—®é¢˜ã€Œwhat's the latest ai news?ã€ä½œä¸ºå‚æ•°è°ƒç”¨ <code>call_agent</code> å¹¶æ¥å±•ç¤ºæ™ºèƒ½ä½“çš„å®é™…è¿è¡Œæ•ˆæœã€‚</mark>

**Code execution:** The Google ADK features integrated components for specialized tasks, including an environment for dynamic code execution. The <code>built_in_code_execution</code> tool provides an agent with a sandboxed Python interpreter. This allows the model to write and run code to perform computational tasks, manipulate data structures, and execute procedural scripts. Such functionality is critical for addressing problems that require deterministic logic and precise calculations, which are outside the scope of probabilistic language generation alone.

<mark><strong>ä»£ç æ‰§è¡Œï¼š</strong>Google ADK è¿˜å†…ç½®äº†ç”¨äºæ‰§è¡ŒåŠ¨æ€ä»£ç çš„ä¸“é—¨ç»„ä»¶ã€‚<code>built_in_code_execution</code> å·¥å…·ä¸ºæ™ºèƒ½ä½“æä¾› Python è§£é‡Šå™¨æ‰§è¡Œçš„æ²™ç®±ç¯å¢ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç¼–å†™å¹¶è¿è¡Œä»£ç æ¥å®Œæˆè®¡ç®—ã€å¤„ç†æ•°æ®å’Œæ‰§è¡Œè„šæœ¬ã€‚å¯¹äºéœ€è¦æ‰§è¡Œç¡®å®šæ€§é€»è¾‘å’Œç²¾ç¡®è®¡ç®—çš„åœºæ™¯ï¼Œè¿™ä¸ªåŠŸèƒ½éå¸¸é‡è¦ï¼Œå› ä¸ºè¿™ç±»é—®é¢˜ä¸æ˜¯æ¦‚ç‡æ€§è¯­è¨€ç”Ÿæˆæ‰€èƒ½è§£å†³çš„ã€‚</mark>

```python
# ä¾èµ–å®‰è£…ï¼š
# pip install google-adk nest-asyncio python-dotenv

import os, getpass
import asyncio
import nest_asyncio
from typing import List
from dotenv import load_dotenv
import logging
from google.adk.agents import Agent as ADKAgent, LlmAgent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.adk.tools import google_search
from google.adk.code_executors import BuiltInCodeExecutor
from google.genai import types

# Define variables required for Session setup and Agent execution
# å®šä¹‰ä¼šè¯å’Œæ™ºèƒ½ä½“æ‰§è¡Œæ‰€éœ€çš„å˜é‡
APP_NAME="calculator"
USER_ID="user1234"
SESSION_ID="session_code_exec_async"


# Agent Definition
# å®šä¹‰ä¸€ä¸ªå¯ä»¥æ‰§è¡Œä»£ç çš„æ™ºèƒ½ä½“
code_agent = LlmAgent(
   name="calculator_agent",
   model="gemini-2.0-flash",
   code_executor=BuiltInCodeExecutor(),
   instruction="""You are a calculator agent.
   When given a mathematical expression, write and execute Python code to calculate the result.
   Return only the final numerical result as plain text, without markdown or code blocks.
   """,
   description="Executes Python code to perform calculations.",
)

# Agent Interaction (Async)
# å¼‚æ­¥æ‰§è¡Œæ™ºèƒ½ä½“
async def call_agent_async(query):

   # Session and Runner
   # åˆ›å»ºä¼šè¯å’Œæ‰§è¡Œå™¨
   session_service = InMemorySessionService()
   session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)
   runner = Runner(agent=code_agent, app_name=APP_NAME, session_service=session_service)

   content = types.Content(role='user', parts=[types.Part(text=query)])
   print(f"\n--- Running Query: {query} ---")
   final_response_text = "No final text response captured."
   try:
       # Use run_async
       # ä½¿ç”¨ run_async æ–¹æ³•å¼‚æ­¥æ‰§è¡Œæ™ºèƒ½ä½“
       async for event in runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content):
           print(f"Event ID: {event.id}, Author: {event.author}")

           # --- Check for specific parts FIRST ---
           # has_specific_part = False
           # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å®šçš„éƒ¨åˆ†
           if event.content and event.content.parts and event.is_final_response():
               for part in event.content.parts: # Iterate through all parts
                   if part.executable_code:
                       # Access the actual code string via .code
                       # é€šè¿‡ .code è·å–æ™ºèƒ½ä½“ç”Ÿæˆçš„ä»£ç 
                       print(f"  Debug: Agent generated code:\n```python\n{part.executable_code.code}\n```")
                       has_specific_part = True
                   elif part.code_execution_result:
                       # Access outcome and output correctly
                       # è·å–ä»£ç æ‰§è¡Œç»“æœå¹¶æ‰“å°è¾“å‡º
                       print(f"  Debug: Code Execution Result: {part.code_execution_result.outcome} - Output:\n{part.code_execution_result.output}")
                       has_specific_part = True
                   # Also print any text parts found in any event for debugging
                   # åŒæ—¶æ‰“å°å…¶ä»–å†…å®¹ï¼Œä¾¿äºè°ƒè¯•
                   elif part.text and not part.text.isspace():
                       print(f"  Text: '{part.text.strip()}'")
                       # Do not set has_specific_part=True here, as we want the final response logic below
                       # ä¸è¦åœ¨è¿™é‡Œè®¾ç½® has_specific_part=Trueï¼Œå› ä¸ºæˆ‘ä»¬è¿˜æƒ³è¦ç»§ç»­ç­‰å¾…æœ€ç»ˆè¾“å‡ºç»“æœ

               # --- Check for final response AFTER specific parts ---
               # ç„¶ååœ¨ç‰¹å®šéƒ¨åˆ†æ£€æŸ¥ä¹‹åå¤„ç†æœ€ç»ˆç»“æœ
               text_parts = [part.text for part in event.content.parts if part.text]
               final_result = "".join(text_parts)
               print(f"==> Final Agent Response: {final_result}")

   except Exception as e:
       print(f"ERROR during agent run: {e}")
   print("-" * 30)

# Main async function to run the examples
# è¿è¡Œç¤ºä¾‹
async def main():
   await call_agent_async("Calculate the value of (5 + 7) * 3")
   await call_agent_async("What is 10 factorial?")


# Execute the main async function
# è¿è¡Œä¸»å¼‚æ­¥å‡½æ•°ä»¥å¯åŠ¨ç¨‹åºæµç¨‹
try:
   nest_asyncio.apply()
   asyncio.run(main())
except RuntimeError as e:
   # Handle specific error when running asyncio.run in an already running loop (like Jupyter/Colab)
   # å¤„ç†åœ¨å·²ç»è¿è¡Œçš„å¾ªç¯ï¼ˆå¦‚ Jupyter/Colabï¼‰ä¸­è¿è¡Œ asyncio.run æ—¶çš„ç‰¹å®šé”™è¯¯
   if "cannot be called from a running event loop" in str(e):
       print("\nRunning in an existing event loop (like Colab/Jupyter).")
       print("Please run `await main()` in a notebook cell instead.")
       # If in an interactive environment like a notebook, you might need to run:
       # åœ¨äº¤äº’å¼ç¯å¢ƒä¸­ï¼ˆå¦‚ Jupyter ç¬”è®°æœ¬ï¼‰ï¼Œä½ å¯èƒ½éœ€è¦è¿è¡Œï¼š
       # await main()
   else:
       raise e # Re-raise other runtime errors

```

è¯‘è€…æ³¨ï¼š[Colab ä»£ç ](https://colab.research.google.com/drive/1iF4I_mkV_as0fYoVBuKtf5gfTONEySfK) å·²ç»´æŠ¤åœ¨[æ­¤å¤„](/codes/Chapter-05-Tool-Use-ADK-Example-Code-Execution.py)ï¼Œå¹¶æ·»åŠ äº†è¾“å‡ºç¤ºä¾‹ã€‚

This script uses Google's Agent Development Kit (ADK) to create an agent that solves mathematical problems by writing and executing Python code. It defines an <code>LlmAgent</code> specifically instructed to act as a calculator, equipping it with the <code>built_in_code_execution</code> tool. The primary logic resides in the <code>call_agent_async</code> function, which sends a user's query to the agent's runner and processes the resulting events. Inside this function, an asynchronous loop iterates through events, printing the generated Python code and its execution result for debugging. The code carefully distinguishes between these intermediate steps and the final event containing the numerical answer. Finally, a <code>main</code> function runs the agent with two different mathematical expressions to demonstrate its ability to perform calculations.

<mark>ä»¥ä¸Šä»£ç æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Google ADK æ¥åˆ›å»ºå…·æœ‰ä»£ç æ‰§è¡Œèƒ½åŠ›çš„æ™ºèƒ½ä½“ï¼Œå®ƒé€šè¿‡ç¼–å†™å’Œæ‰§è¡Œ Python ä»£ç æ¥è§£å†³å…·ä½“çš„æ•°å­¦é—®é¢˜ã€‚</mark>

<mark>æ¥ç€åˆ›å»ºä¸€ä¸ªåä¸º <code>code_agent</code> çš„æ™ºèƒ½ä½“å®ä¾‹ï¼Œè¯¦ç»†æè¿°æ™ºèƒ½ä½“çš„åŠŸèƒ½å’ŒæŒ‡ä»¤ï¼Œè¦æ±‚å®ƒæ‰®æ¼”è®¡ç®—å™¨çš„è§’è‰²ï¼Œå¹¶å¯ä»¥ä½¿ç”¨å†…ç½®çš„ <code>built_in_code_execution</code> å·¥å…·æ¥æ‰§è¡Œä»£ç ã€‚</mark>

<mark>æ ¸å¿ƒé€»è¾‘ä½äº <code>call_agent_async</code> å‡½æ•°ä¸­ï¼Œè¯¥å‡½æ•°å°†ç”¨æˆ·æŸ¥è¯¢å‘é€ç»™æ™ºèƒ½ä½“çš„è¿è¡Œå™¨å¹¶å¤„ç†è¿”å›çš„äº‹ä»¶ã€‚åœ¨è¯¥å‡½æ•°å†…éƒ¨ï¼Œä½¿ç”¨å¼‚æ­¥å¾ªç¯éå†äº‹ä»¶ï¼Œæ‰“å°ç”Ÿæˆçš„ Python ä»£ç åŠå…¶æ‰§è¡Œç»“æœã€‚ä»£ç åŒºåˆ†äº†è¿™äº›ä¸­é—´æ­¥éª¤å’ŒåŒ…å«æœ€ç»ˆç­”æ¡ˆçš„ç»“æŸäº‹ä»¶ã€‚</mark>

<mark>æœ€åï¼Œ<code>main</code> å‡½æ•°ç”¨ä¸¤ä¸ªä¸åŒçš„æ•°å­¦è¡¨è¾¾å¼è¿è¡Œæ™ºèƒ½ä½“ï¼Œä»¥æ¼”ç¤ºå…¶æ‰§è¡Œè®¡ç®—çš„èƒ½åŠ›ã€‚</mark>

**Enterprise search:** This code defines a Google ADK application using the google.adk library in Python. It specifically uses a <code>VSearchAgent</code>, which is designed to answer questions by searching a specified Vertex AI Search datastore. The code initializes a <code>VSearchAgent</code> named "q2_strategy_vsearch_agent", providing a description, the model to use ("gemini-2.0-flash-exp"), and the ID of the Vertex AI Search datastore. The <code>DATASTORE_ID</code> is expected to be set as an environment variable. It then sets up a <code>Runner</code> for the agent, using an <code>InMemorySessionService</code> to manage conversation history. An asynchronous function <code>call_vsearch_agent_async</code> is defined to interact with the agent. This function takes a query, constructs a message content object, and calls the runner's <code>run_async</code> method to send the query to the agent. The function then streams the agent's response back to the console as it arrives. It also prints information about the final response, including any source attributions from the datastore. Error handling is included to catch exceptions during the agent's execution, providing informative messages about potential issues like an incorrect datastore ID or missing permissions. Another asynchronous function <code>run_vsearch_example</code> is provided to demonstrate how to call the agent with example queries. The main execution block checks if the <code>DATASTORE_ID</code> is set and then runs the example using <code>asyncio.run</code>. It includes a check to handle cases where the code is run in an environment that already has a running event loop, like a Jupyter notebook.

<mark><strong>ä¼ä¸šæœç´¢ï¼š</strong>ä¸‹é¢è¿™æ®µ Python ä»£ç ä½¿ç”¨ <code>google.adk</code> åº“å®šä¹‰äº†ä¸€ä¸ª Google ADK åº”ç”¨ï¼Œä½¿ç”¨ <code>VSearchAgent</code> å·¥å…·æœç´¢ Vertex AI Search æ•°æ®æ¥å›ç­”é—®é¢˜ã€‚</mark>

<mark>ä»£ç å…ˆåˆ›å»ºäº†ä¸€ä¸ªåä¸º <code>q2_strategy_vsearch_agent</code> çš„ <code>VSearchAgent</code> ç¤ºä¾‹ï¼Œæä¾›è¯¦ç»†çš„æè¿°ã€ä½¿ç”¨çš„æ¨¡å‹ï¼ˆgemini-2.0-flash-expï¼‰ä»¥åŠ Vertex AI Search æ•°æ®å­˜å‚¨çš„ IDï¼Œå…¶ä¸­ <code>DATASTORE_ID</code> éœ€è¦é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®ã€‚</mark>

<mark>æ¥ç€ä¸ºæ™ºèƒ½ä½“è®¾ç½® <code>Runner</code> å®ä¾‹ï¼Œå¹¶ä½¿ç”¨ <code>InMemorySessionService</code> æ¥ç®¡ç†å¯¹è¯å†å²ã€‚</mark>

<mark>æ ¸å¿ƒçš„å¼‚æ­¥å‡½æ•° <code>call_vsearch_agent_async</code> ç”¨äºä¸æ™ºèƒ½ä½“äº¤äº’ï¼Œè¯¥å‡½æ•°æ¥æ”¶æŸ¥è¯¢è¯·æ±‚æ„é€ ä¸ºæ¶ˆæ¯å¯¹è±¡ï¼Œå¹¶ä½œä¸ºå‚æ•°ä¼ ç»™ <code>run_async</code> æ–¹æ³•ä»è€Œå®ç°å°†æŸ¥è¯¢è¯·æ±‚å‘é€ç»™æ™ºèƒ½ä½“å¹¶ç­‰å¾…å¼‚æ­¥äº‹ä»¶è¿”å›ã€‚</mark>

<mark>éšåè¯¥å‡½æ•°ä»¥æµå¼æ–¹å¼å°†æ™ºèƒ½ä½“çš„å“åº”è¾“å‡ºåˆ°æ§åˆ¶å°ï¼Œå¹¶æ‰“å°å…³äºæœ€ç»ˆå“åº”çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ¥è‡ªæ•°æ®å­˜å‚¨çš„å¼•ç”¨æ¥æºã€‚ä»£ç å…·å¤‡é”™è¯¯å¤„ç†æœºåˆ¶ï¼Œä»¥æ•è·æ™ºèƒ½ä½“æ‰§è¡ŒæœŸé—´çš„å¼‚å¸¸ï¼Œå¹¶æä¾›æœ‰ä»·å€¼çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚æ•°æ®å­˜å‚¨ ID ä¸æ­£ç¡®æˆ–æƒé™ç¼ºå¤±ç­‰ã€‚</mark>

<mark>å¦ä¸€ä¸ªå¼‚æ­¥å‡½æ•° <code>run_vsearch_example</code> ç”¨äºæ¼”ç¤ºå¦‚ä½•è°ƒç”¨è¯¥æ™ºèƒ½ä½“ã€‚ä¸»æ‰§è¡Œå—å…ˆæ£€æŸ¥ <code>DATASTORE_ID</code> æ˜¯å¦å·²è®¾ç½®ï¼Œç„¶åä½¿ç”¨ <code>asyncio.run</code> è¿è¡Œç¤ºä¾‹ã€‚ä»£ç æœ€åè¿˜åŒ…å«ä¸€ä¸ªå¼‚å¸¸æ£€æŸ¥ï¼Œé¿å…åœ¨å·²æœ‰è¿è¡Œäº‹ä»¶å¾ªç¯çš„ç¯å¢ƒï¼ˆå¦‚ Jupyter notebookï¼‰ä¸­è¿è¡Œä»£ç æ—¶å‡ºç°é”™è¯¯ã€‚</mark>

```python
# Colab ä»£ç é“¾æ¥ï¼šhttps://colab.research.google.com/drive/1AhF4Jam8wuYMEYU27y22r1uTbixs9MSE

# ä¾èµ–å®‰è£…ï¼š
# pip install google-adk nest-asyncio python-dotenv

import asyncio
from google.genai import types
from google.adk import agents
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
import os

# --- Configuration ---
# --- ç¯å¢ƒå˜é‡é…ç½® ---
# Ensure you have set your GOOGLE_API_KEY and DATASTORE_ID environment variables
# è¯·ç¡®è®¤å·²åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½® GOOGLE_API_KEY å’Œ DATASTORE_ID

# For example:
# os.environ["GOOGLE_API_KEY"] = "YOUR_API_KEY"
# os.environ["DATASTORE_ID"] = "YOUR_DATASTORE_ID"

DATASTORE_ID = os.environ.get("DATASTORE_ID")

# --- Application Constants ---
# --- å®šä¹‰å¸¸é‡ ---
APP_NAME = "vsearch_app"
USER_ID = "user_123"  # Example User ID
SESSION_ID = "session_456" # Example Session ID

# --- Agent Definition (Updated with the newer model from the guide) ---
# --- å®šä¹‰ä¸€ä¸ªä½¿ç”¨ Vertex AI Search æ•°æ®å­˜å‚¨çš„æ™ºèƒ½ä½“ ---
vsearch_agent = agents.VSearchAgent(
    name="q2_strategy_vsearch_agent",
    description="Answers questions about Q2 strategy documents using Vertex AI Search.",
    model="gemini-2.0-flash-exp", # Updated model based on the guide's examples
    datastore_id=DATASTORE_ID,
    model_parameters={"temperature": 0.0}
)

# --- Runner and Session Initialization ---
# --- åˆå§‹åŒ–æ‰§è¡Œå™¨å’Œä¼šè¯ ---
runner = Runner(
    agent=vsearch_agent,
    app_name=APP_NAME,
    session_service=InMemorySessionService(),
)

# --- Agent Invocation Logic ---
# --- æ™ºèƒ½ä½“è°ƒç”¨é€»è¾‘ ---
async def call_vsearch_agent_async(query: str):
    """
    Initializes a session and streams the agent's response.
    åˆå§‹åŒ–ä¼šè¯å¹¶ä½¿ç”¨æµå¼è¾“å‡ºæ™ºèƒ½ä½“çš„å“åº”ã€‚
    """
    print(f"User: {query}")
    print("Agent: ", end="", flush=True)

    try:
        # Construct the message content correctly
        # æ„é€ æ¶ˆæ¯å¯¹è±¡
        content = types.Content(role='user', parts=[types.Part(text=query)])

        # Process events as they arrive from the asynchronous runner
        # æ‰§è¡Œå¹¶å¤„ç†å¼‚æ­¥äº‹ä»¶
        async for event in runner.run_async(
            user_id=USER_ID,
            session_id=SESSION_ID,
            new_message=content
        ):
            # For token-by-token streaming of the response text
            # å¤„ç†æµå¼è¾“å‡ºçš„æ–‡æœ¬
            if hasattr(event, 'content_part_delta') and event.content_part_delta:
                print(event.content_part_delta.text, end="", flush=True)

            # Process the final response and its associated metadata
            # å¤„ç†æœ€ç»ˆè¾“å‡ºåŠå…¶å…³è”çš„å…ƒæ•°æ®
            if event.is_final_response():
                print() # Newline after the streaming response
                if event.grounding_metadata:
                    print(f"  (Source Attributions: {len(event.grounding_metadata.grounding_attributions)} sources found)")
                else:
                    print("  (No grounding metadata found)")
                print("-" * 30)

    except Exception as e:
        print(f"\nAn error occurred: {e}")
        print("Please ensure your datastore ID is correct and that the service account has the necessary permissions.")
        print("-" * 30)

# --- Run Example ---
# --- è¿è¡Œç¤ºä¾‹ ---
async def run_vsearch_example():
    # Replace with a question relevant to YOUR datastore content
    # è¯·å°†æ­¤å¤„çš„ç¤ºä¾‹é—®é¢˜æ›¿æ¢ä¸ºä¸æ‚¨æ•°æ®å­˜å‚¨å†…å®¹ç›¸å…³ã€å…·ä½“çš„é—®é¢˜
    await call_vsearch_agent_async("Summarize the main points about the Q2 strategy document.")
    await call_vsearch_agent_async("What safety procedures are mentioned for lab X?")

# --- Execution ---
# --- æ‰§è¡Œ ---
if __name__ == "__main__":
    if not DATASTORE_ID:
        print("Error: DATASTORE_ID environment variable is not set.")
    else:
        try:
            asyncio.run(run_vsearch_example())
        except RuntimeError as e:
            # This handles cases where asyncio.run is called in an environment
            # that already has a running event loop (like a Jupyter notebook).
            # å¤„ç†åœ¨å·²ç»è¿è¡Œçš„å¾ªç¯ï¼ˆå¦‚ Jupyter notebookï¼‰ä¸­è¿è¡Œ asyncio.run æ—¶çš„ç‰¹å®šé”™è¯¯
            if "cannot be called from a running event loop" in str(e):
                print("Skipping execution in a running event loop. Please run this script directly.")
            else:
                raise e
```

è¯‘è€…æ³¨ï¼š[Colab ä»£ç ](https://colab.research.google.com/drive/1AhF4Jam8wuYMEYU27y22r1uTbixs9MSE) å·²ç»´æŠ¤åœ¨[æ­¤å¤„](/codes/Chapter-05-Tool-Use-ADK-Example-AI-Search.py)ã€‚

Overall, this code provides a basic framework for building a conversational AI application that leverages Vertex AI Search to answer questions based on information stored in a datastore. It demonstrates how to define an agent, set up a runner, and interact with the agent asynchronously while streaming the response. The focus is on retrieving and synthesizing information from a specific datastore to answer user queries.

<mark>æ€»ç»“ä¸€ä¸‹ï¼Œè¿™æ®µä»£ç æä¾›äº†ç”¨äºæ„å»ºå¯¹è¯å¼ AI åº”ç”¨çš„åŸºæœ¬æ¡†æ¶ï¼Œè¯¥åº”ç”¨é€šè¿‡æŸ¥è¯¢ Vertex AI Search ä¸­çš„æ•°æ®æ¥å›ç­”é—®é¢˜ã€‚ç¤ºä¾‹è¯¦ç»†å±•ç¤ºäº†å¦‚ä½•å®šä¹‰æ™ºèƒ½ä½“ã€é…ç½®æ‰§è¡Œå™¨ï¼Œä»¥åŠå¦‚ä½•åœ¨å¼‚æ­¥äº¤äº’ä¸­ä»¥æµå¼æ–¹å¼æ¥æ”¶å“åº”ã€‚æœ€ç»ˆè¾¾åˆ°äº†ä»æŒ‡å®šçš„æ•°æ®å­˜å‚¨ä¸­æ£€ç´¢ä¿¡æ¯å¹¶å°†å…¶æ•´åˆä»¥å›ç­”ç”¨æˆ·æé—®çš„ç›®çš„ã€‚</mark>

**Vertex Extensions:** A Vertex AI extension is a structured API wrapper that enables a model to connect with external APIs for real-time data processing and action execution. Extensions offer enterprise-grade security, data privacy, and performance guarantees. They can be used for tasks like generating and running code, querying websites, and analyzing information from private datastores. Google provides prebuilt extensions for common use cases like Code Interpreter and Vertex AI Search, with the option to create custom ones. The primary benefit of extensions includes strong enterprise controls and seamless integration with other Google products. The key difference between extensions and function calling lies in their execution: Vertex AI automatically executes extensions, whereas function calls require manual execution by the user or client.

<mark><strong>Vertex æ‰©å±•ï¼šVertex AI æ‰©å±•æ˜¯å¯¹å¤–éƒ¨æ¥å£çš„ç»“æ„åŒ–å°è£…ï¼Œå…è®¸æ¨¡å‹ç›´æ¥è¿æ¥å¤–éƒ¨æœåŠ¡ä»¥å®ç°å®æ—¶æ•°æ®çš„å¤„ç†å’Œæ“ä½œã€‚æ‰©å±•æä¾›ä¼ä¸šçº§çš„å®‰å…¨ã€æ•°æ®éšç§ä¿æŠ¤å’Œæ€§èƒ½ä¿éšœï¼Œé€‚ç”¨äºç”Ÿæˆä¸è¿è¡Œä»£ç ã€æŸ¥è¯¢ç½‘ç«™ã€åˆ†æç§æœ‰æ•°æ®ç­‰åœºæ™¯ã€‚Google æä¾›äº†è¯¸å¦‚ä»£ç è§£é‡Šå™¨å’Œ Vertex AI Search çš„é¢„ç½®æ‰©å±•ï¼Œå½“ç„¶ä¹Ÿæ”¯æŒè‡ªå®šä¹‰æ‰©å±•ã€‚å®ƒä»¬çš„æ ¸å¿ƒä¼˜åŠ¿æ˜¯å¼ºå¤§çš„ä¼ä¸šæ§åˆ¶èƒ½åŠ›ä»¥åŠä¸ Google ç”Ÿæ€çš„æ— ç¼è¡”æ¥ã€‚ä¸å‡½æ•°è°ƒç”¨ä¸åŒçš„æ˜¯ï¼ŒVertex AI ä¼šè‡ªåŠ¨æ‰§è¡Œæ‰©å±•ï¼Œè€Œå‡½æ•°è°ƒç”¨é€šå¸¸éœ€è¦ç”±ç”¨æˆ·æˆ–å®¢æˆ·ç«¯æ¥è§¦å‘å’Œæ‰§è¡Œã€‚</strong></mark>

---

## At a Glance | <mark>è¦ç‚¹é€Ÿè§ˆ</mark>

**What:** LLMs are powerful text generators, but they are fundamentally disconnected from the outside world. Their knowledge is static, limited to the data they were trained on, and they lack the ability to perform actions or retrieve real-time information. This inherent limitation prevents them from completing tasks that require interaction with external APIs, databases, or services. Without a bridge to these external systems, their utility for solving real-world problems is severely constrained.

<mark><strong>é—®é¢˜æ‰€åœ¨ï¼š</strong>å¤§è¯­è¨€æ¨¡å‹æ˜¯å¼ºå¤§çš„æ–‡æœ¬ç”Ÿæˆå™¨ï¼Œä½†å®ƒä»¬æœ¬è´¨ä¸Šä¸å¤–éƒ¨ä¸–ç•Œè„±èŠ‚ã€‚å®ƒä»¬çš„çŸ¥è¯†æ˜¯é™æ€çš„ï¼Œä»…é™äºè®­ç»ƒæ—¶æ‰€ç”¨çš„æ•°æ®ï¼Œå¹¶ä¸”ç¼ºä¹æ‰§è¡Œæ“ä½œæˆ–æ£€ç´¢å®æ—¶ä¿¡æ¯çš„èƒ½åŠ›ã€‚è¿™ç§å›ºæœ‰çš„å±€é™æ€§ä½¿å®ƒä»¬æ— æ³•å®Œæˆéœ€è¦ä¸å¤–éƒ¨æ¥å£ã€æ•°æ®åº“ã€æœåŠ¡è¿›è¡Œäº¤äº’çš„ä»»åŠ¡ã€‚å¦‚æœæ²¡æœ‰è¿æ¥è¿™äº›å¤–éƒ¨ç³»ç»Ÿçš„æ¡¥æ¢ï¼Œå®ƒä»¬åœ¨è§£å†³å®é™…é—®é¢˜çš„èƒ½åŠ›å°†å¤§æ‰“æŠ˜æ‰£ã€‚</mark>

**Why:** The Tool Use pattern, often implemented via function calling, provides a standardized solution to this problem. It works by describing available external functions, or "tools," to the LLM in a way it can understand. Based on a user's request, the agentic LLM can then decide if a tool is needed and generate a structured data object (like a JSON) specifying which function to call and with what arguments. An orchestration layer executes this function call, retrieves the result, and feeds it back to the LLM. This allows the LLM to incorporate up-to-date, external information or the result of an action into its final response, effectively giving it the ability to act.

<mark><strong>è§£å†³ä¹‹é“ï¼š</strong>å·¥å…·ä½¿ç”¨æ¨¡å¼ï¼ˆé€šå¸¸é€šè¿‡å‡½æ•°è°ƒç”¨æœºåˆ¶å®ç°ï¼‰ä¸ºè¿™ä¸ªé—®é¢˜æä¾›äº†æ ‡å‡†åŒ–è§£å†³æ–¹æ¡ˆã€‚å®ƒçš„å·¥ä½œåŸç†æ˜¯ï¼Œä»¥å¤§è¯­è¨€æ¨¡å‹èƒ½ç†è§£çš„æ–¹å¼å‘å…¶æè¿°å¯ç”¨çš„å¤–éƒ¨å‡½æ•°æˆ–å·¥å…·ã€‚åŸºäºç”¨æˆ·è¯·æ±‚ï¼Œå…·æœ‰æ™ºèƒ½èƒ½åŠ›çš„æ¨¡å‹å¯ä»¥åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œå¹¶ç”Ÿæˆç»“æ„åŒ–æ•°æ®å¯¹è±¡ï¼ˆå¦‚ JSONï¼‰ï¼ŒæŒ‡æ˜è¦è°ƒç”¨å“ªä¸ªå‡½æ•°ä»¥åŠä½¿ç”¨ä»€ä¹ˆå‚æ•°ã€‚ç¼–æ’å±‚è´Ÿè´£æ‰§è¡Œæ­¤å‡½æ•°è°ƒç”¨ï¼Œè·å–ç»“æœï¼Œå¹¶å°†å…¶åé¦ˆç»™æ¨¡å‹ã€‚è¿™ä½¿å¾—å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿå°†æœ€æ–°çš„å¤–éƒ¨ä¿¡æ¯æˆ–æ“ä½œç»“æœæ•´åˆåˆ°æœ€ç»ˆå“åº”ä¸­ï¼Œä»è€Œæœ‰æ•ˆåœ°èµ‹äºˆäº†å®ƒè¡ŒåŠ¨çš„èƒ½åŠ›ã€‚</mark>

**Rule of thumb:** Use the Tool Use pattern whenever an agent needs to break out of the LLM's internal knowledge and interact with the outside world. This is essential for tasks requiring real-time data (e.g., checking weather, stock prices), accessing private or proprietary information (e.g., querying a company's database), performing precise calculations, executing code, or triggering actions in other systems (e.g., sending an email, controlling smart devices).

<mark><strong>ç»éªŒæ³•åˆ™ï¼š</strong>å½“æ™ºèƒ½ä½“éœ€è¦çªç ´å¤§è¯­è¨€æ¨¡å‹å†…éƒ¨çŸ¥è¯†å±€é™å¹¶ä¸å¤–éƒ¨ä¸–ç•Œäº’åŠ¨æ—¶ï¼Œå°±åº”è¯¥ä½¿ç”¨å·¥å…·ä½¿ç”¨æ¨¡å¼ã€‚è¿™å¯¹äºéœ€è¦å®æ—¶æ•°æ®ï¼ˆå¦‚æŸ¥è¯¢å¤©æ°”ã€è‚¡ç¥¨ä»·æ ¼ï¼‰ã€è®¿é—®ç§æœ‰æˆ–ä¸“æœ‰ä¿¡æ¯ï¼ˆå¦‚æŸ¥è¯¢å…¬å¸æ•°æ®åº“ï¼‰ã€æ‰§è¡Œç²¾ç¡®è®¡ç®—ã€æ‰§è¡Œä»£ç æˆ–åœ¨å…¶ä»–ç³»ç»Ÿä¸­è§¦å‘æ“ä½œï¼ˆå¦‚å‘é€é‚®ä»¶ã€æ§åˆ¶æ™ºèƒ½è®¾å¤‡ï¼‰çš„ä»»åŠ¡è‡³å…³é‡è¦ã€‚</mark>

**Visual summary:** | <mark><strong>å¯è§†åŒ–æ€»ç»“ï¼š</strong></mark>

![Tool Use Design Pattern](/images/chapter05_fig2.jpg)

Fig.2: Tool use design pattern

<mark>å›¾ 2ï¼šå·¥å…·ä½¿ç”¨æ¨¡å¼</mark>

---

## Key Takeaways | <mark>æ ¸å¿ƒè¦ç‚¹</mark>

- Tool Use (Function Calling) allows agents to interact with external systems and access dynamic information.

   <mark>å·¥å…·ä½¿ç”¨ï¼ˆå‡½æ•°è°ƒç”¨ï¼‰æ¨¡å¼ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’å¹¶è·å–åŠ¨æ€ä¿¡æ¯ã€‚</mark>

- It involves defining tools with clear descriptions and parameters that the LLM can understand.

   <mark>è¿™åŒ…æ‹¬ä¸ºå·¥å…·å®šä¹‰æ¸…æ™°çš„æè¿°å’Œå‚æ•°ï¼Œä»¥ä¾¿å¤§è¯­è¨€æ¨¡å‹èƒ½æ­£ç¡®ä½¿ç”¨è¿™äº›å·¥å…·ã€‚</mark>

- The LLM decides when to use a tool and generates structured function calls.

   <mark>å¤§è¯­è¨€æ¨¡å‹ä¼šå†³å®šä½•æ—¶ä½¿ç”¨å·¥å…·ï¼Œå¹¶ç”Ÿæˆç»“æ„åŒ–çš„æ•°æ®ä»¥æ‰§è¡Œè¿™äº›æ“ä½œã€‚</mark>

- Agentic frameworks execute the actual tool calls and return the results to the LLM.

   <mark>æ™ºèƒ½ä½“æ¡†æ¶è´Ÿè´£æ‰§è¡Œå®é™…çš„å·¥å…·è°ƒç”¨ï¼Œå¹¶å°†ç»“æœè¿”å›ç»™å¤§è¯­è¨€æ¨¡å‹ã€‚</mark>

- Tool Use is essential for building agents that can perform real-world actions and provide up-to-date information.

   <mark>å·¥å…·ä½¿ç”¨æ¨¡å¼å¯¹äºæ„å»ºèƒ½å¤Ÿæ‰§è¡Œç°å®ä»»åŠ¡å¹¶æä¾›æœ€æ–°ä¿¡æ¯çš„æ™ºèƒ½ä½“æ¥è¯´è‡³å…³é‡è¦ã€‚</mark>

- LangChain simplifies tool definition using the @tool decorator and provides create_tool_calling_agent and AgentExecutor for building tool-using agents.

   <mark>LangChain ä½¿ç”¨ <code>@tool</code> è£…é¥°å™¨ç®€åŒ–å·¥å…·å®šä¹‰ï¼Œå¹¶æä¾› <code>create_tool_calling_agent</code> å’Œ <code>AgentExecutor</code> æ¥æ„å»ºèƒ½å¤Ÿä½¿ç”¨å·¥å…·çš„æ™ºèƒ½ä½“ã€‚</mark>

- Google ADK has a number of very useful pre-built tools such as Google Search, Code Execution and Vertex AI Search Tool.

   <mark>Google ADK æä¾›äº†å¤šç§éå¸¸å®ç”¨çš„å†…ç½®å·¥å…·ï¼Œæ¯”å¦‚ Google æœç´¢ã€ä»£ç æ‰§è¡Œå™¨å’Œ Vertex AI Search å·¥å…·ï¼Œæ–¹ä¾¿å°†å¤–éƒ¨åŠŸèƒ½ç›´æ¥é›†æˆåˆ°å·¥ä½œæµç¨‹ä¸­ã€‚</mark>

---

## Conclusion | <mark>ç»“è¯­</mark>

The Tool Use pattern is a critical architectural principle for extending the functional scope of large language models beyond their intrinsic text generation capabilities. By equipping a model with the ability to interface with external software and data sources, this paradigm allows an agent to perform actions, execute computations, and retrieve information from other systems. This process involves the model generating a structured request to call an external tool when it determines that doing so is necessary to fulfill a user's query. Frameworks such as LangChain, Google ADK, and Crew AI offer structured abstractions and components that facilitate the integration of these external tools. These frameworks manage the process of exposing tool specifications to the model and parsing its subsequent tool-use requests. This simplifies the development of sophisticated agentic systems that can interact with and take action within external digital environments.

<mark>å·¥å…·ä½¿ç”¨æ¨¡å¼æ˜¯ä¸€ç§é‡è¦çš„æ¶æ„åŸåˆ™ï¼Œç”¨äºæŠŠå¤§å‹è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›æ‰©å±•åˆ°çº¯æ–‡æœ¬ç”Ÿæˆä¹‹å¤–ã€‚é€šè¿‡è®©æ¨¡å‹èƒ½å¤Ÿä¸å¤–éƒ¨è½¯ä»¶å’Œæ•°æ®æºå¯¹æ¥ï¼Œè¿™ä¸€æ¨¡å¼ä½¿å¾—æ™ºèƒ½ä½“å¯ä»¥æ‰§è¡Œæ“ä½œã€å®Œæˆè®¡ç®—ä»¥åŠä»å…¶ä»–ç³»ç»Ÿè·å–ä¿¡æ¯ã€‚å½“æ¨¡å‹åˆ¤æ–­éœ€è¦è°ƒç”¨å¤–éƒ¨å·¥å…·æ¥æ»¡è¶³ç”¨æˆ·è¯·æ±‚æ—¶ï¼Œå®ƒä¼šç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„è°ƒç”¨è¯·æ±‚ã€‚</mark>

<mark>åƒ LangChainã€Google ADK å’Œ Crew AI è¿™æ ·çš„æ¡†æ¶æä¾›äº†ä¾¿äºé›†æˆå¤–éƒ¨å·¥å…·çš„æŠ½è±¡å±‚å’Œç»„ä»¶ï¼Œè´Ÿè´£å‘æ¨¡å‹æš´éœ²å·¥å…·çš„å®šä¹‰å¹¶è§£ææ¨¡å‹è¿”å›çš„å·¥å…·è°ƒç”¨è¯·æ±‚ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™å¤§å¤§ç®€åŒ–äº†èƒ½å¤Ÿåœ¨å¤–éƒ¨æ•°å­—ç¯å¢ƒä¸­æ„ŸçŸ¥ã€äº¤äº’å’Œè¡ŒåŠ¨çš„å¤æ‚æ™ºèƒ½ä½“ç³»ç»Ÿçš„å¼€å‘ã€‚</mark>

---

## References | <mark>å‚è€ƒæ–‡çŒ®</mark>

1. LangChain Documentation (Tools): <https://python.langchain.com/docs/integrations/tools/>

   <mark>LangChain æ–‡æ¡£ï¼ˆå·¥å…·ä½¿ç”¨ï¼‰ï¼š<https://python.langchain.com/docs/integrations/tools/></mark>

2. Google Agent Developer Kit (ADK) Documentation (Tools): <https://google.github.io/adk-docs/tools/>

   <mark>Google å¼€å‘è€…å¥—ä»¶ï¼ˆADKï¼‰æ–‡æ¡£ï¼ˆå·¥å…·ä½¿ç”¨ï¼‰ï¼š<https://google.github.io/adk-docs/tools/></mark>

3. OpenAI Function Calling Documentation: <https://platform.openai.com/docs/guides/function-calling>

   <mark>OpenAI å‡½æ•°è°ƒç”¨æ–‡æ¡£ï¼š<https://platform.openai.com/docs/guides/function-calling></mark>

4. CrewAI Documentation (Tools): <https://docs.crewai.com/concepts/tools>

   <mark>CrewAI æ–‡æ¡£ï¼ˆå·¥å…·ä½¿ç”¨ï¼‰ï¼š<https://docs.crewai.com/concepts/tools></mark>
